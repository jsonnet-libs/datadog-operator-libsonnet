{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='datadogAgent', url='', help='"DatadogAgent Deployment with the Datadog Operator."'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of DatadogAgent', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'datadoghq.com/v2alpha1',
    kind: 'DatadogAgent',
  } + self.metadata.withName(name=name),
  '#spec':: d.obj(help='"DatadogAgentSpec defines the desired state of DatadogAgent"'),
  spec: {
    '#features':: d.obj(help='"Features running on the Agent and Cluster Agent"'),
    features: {
      '#admissionController':: d.obj(help='"AdmissionController configuration."'),
      admissionController: {
        '#agentSidecarInjection':: d.obj(help='"AgentSidecarInjection contains Agent sidecar injection configurations."'),
        agentSidecarInjection: {
          '#image':: d.obj(help='"Image overrides the default Agent image name and tag for the Agent sidecar."'),
          image: {
            '#pullSecrets':: d.obj(help='"It is possible to specify Docker registry credentials.\\nSee https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod"'),
            pullSecrets: {
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
            },
            '#withJmxEnabled':: d.fn(help='"Define whether the Agent image should support JMX.\\nTo be used if the `Name` field does not correspond to a full image string."', args=[d.arg(name='jmxEnabled', type=d.T.boolean)]),
            withJmxEnabled(jmxEnabled): { spec+: { features+: { admissionController+: { agentSidecarInjection+: { image+: { jmxEnabled: jmxEnabled } } } } } },
            '#withName':: d.fn(help='"Defines the Agent image name for the pod. You can provide this as:\\n* `<NAME>` - Use `agent` for the Datadog Agent, `cluster-agent` for the Datadog Cluster Agent, or `dogstatsd`\\nfor DogStatsD. The full image string is derived from `global.registry`, `[key].image.tag`, and `[key].image.jmxEnabled`.\\n* `<NAME>:<TAG>` - For example, `agent:latest`. The registry is derived from `global.registry`. `[key].image.tag`\\nand `[key].image.jmxEnabled` are ignored.\\n* `<REGISTRY>/<NAME>:<TAG>` - For example, `gcr.io/datadoghq/agent:latest`. If the full image string is specified\\n  like this, then `global.registry`, `[key].image.tag`, and `[key].image.jmxEnabled` are ignored."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { features+: { admissionController+: { agentSidecarInjection+: { image+: { name: name } } } } } },
            '#withPullPolicy':: d.fn(help='"The Kubernetes pull policy:\\nUse `Always`, `Never`, or `IfNotPresent`."', args=[d.arg(name='pullPolicy', type=d.T.string)]),
            withPullPolicy(pullPolicy): { spec+: { features+: { admissionController+: { agentSidecarInjection+: { image+: { pullPolicy: pullPolicy } } } } } },
            '#withPullSecrets':: d.fn(help='"It is possible to specify Docker registry credentials.\\nSee https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod"', args=[d.arg(name='pullSecrets', type=d.T.array)]),
            withPullSecrets(pullSecrets): { spec+: { features+: { admissionController+: { agentSidecarInjection+: { image+: { pullSecrets: if std.isArray(v=pullSecrets) then pullSecrets else [pullSecrets] } } } } } },
            '#withPullSecretsMixin':: d.fn(help='"It is possible to specify Docker registry credentials.\\nSee https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='pullSecrets', type=d.T.array)]),
            withPullSecretsMixin(pullSecrets): { spec+: { features+: { admissionController+: { agentSidecarInjection+: { image+: { pullSecrets+: if std.isArray(v=pullSecrets) then pullSecrets else [pullSecrets] } } } } } },
            '#withTag':: d.fn(help='"Define the image tag to use.\\nTo be used if the `Name` field does not correspond to a full image string."', args=[d.arg(name='tag', type=d.T.string)]),
            withTag(tag): { spec+: { features+: { admissionController+: { agentSidecarInjection+: { image+: { tag: tag } } } } } },
          },
          '#profiles':: d.obj(help='"Profiles define the sidecar configuration override. Only one profile is supported."'),
          profiles: {
            '#env':: d.obj(help='"EnvVars specifies the environment variables for the profile."'),
            env: {
              '#valueFrom':: d.obj(help="\"Source for the environment variable's value. Cannot be used if value is not empty.\""),
              valueFrom: {
                '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
                configMapKeyRef: {
                  '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { valueFrom+: { configMapKeyRef+: { key: key } } },
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { valueFrom+: { configMapKeyRef+: { name: name } } },
                  '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                  withOptional(optional): { valueFrom+: { configMapKeyRef+: { optional: optional } } },
                },
                '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
                fieldRef: {
                  '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                  withApiVersion(apiVersion): { valueFrom+: { fieldRef+: { apiVersion: apiVersion } } },
                  '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                  withFieldPath(fieldPath): { valueFrom+: { fieldRef+: { fieldPath: fieldPath } } },
                },
                '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
                resourceFieldRef: {
                  '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                  withContainerName(containerName): { valueFrom+: { resourceFieldRef+: { containerName: containerName } } },
                  '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                  withDivisor(divisor): { valueFrom+: { resourceFieldRef+: { divisor: divisor } } },
                  '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                  withResource(resource): { valueFrom+: { resourceFieldRef+: { resource: resource } } },
                },
                '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
                secretKeyRef: {
                  '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { valueFrom+: { secretKeyRef+: { key: key } } },
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { valueFrom+: { secretKeyRef+: { name: name } } },
                  '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                  withOptional(optional): { valueFrom+: { secretKeyRef+: { optional: optional } } },
                },
              },
              '#withName':: d.fn(help='"Name of the environment variable. Must be a C_IDENTIFIER."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#resources':: d.obj(help='"ResourceRequirements specifies the resource requirements for the profile."'),
            resources: {
              '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
              claims: {
                '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
                withRequest(request): { request: request },
              },
              '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
              withClaims(claims): { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } },
              '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
              withClaimsMixin(claims): { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } },
              '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
              withLimits(limits): { resources+: { limits: limits } },
              '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
              withLimitsMixin(limits): { resources+: { limits+: limits } },
              '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
              withRequests(requests): { resources+: { requests: requests } },
              '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
              withRequestsMixin(requests): { resources+: { requests+: requests } },
            },
            '#securityContext':: d.obj(help='"SecurityContext specifies the security context for the profile."'),
            securityContext: {
              '#appArmorProfile':: d.obj(help="\"appArmorProfile is the AppArmor options to use by this container. If set, this profile\\noverrides the pod's appArmorProfile.\\nNote that this field cannot be set when spec.os.name is windows.\""),
              appArmorProfile: {
                '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
                withLocalhostProfile(localhostProfile): { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } },
                '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { securityContext+: { appArmorProfile+: { type: type } } },
              },
              '#capabilities':: d.obj(help='"The capabilities to add/drop when running containers.\\nDefaults to the default set of capabilities granted by the container runtime.\\nNote that this field cannot be set when spec.os.name is windows."'),
              capabilities: {
                '#withAdd':: d.fn(help='"Added capabilities"', args=[d.arg(name='add', type=d.T.array)]),
                withAdd(add): { securityContext+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } },
                '#withAddMixin':: d.fn(help='"Added capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
                withAddMixin(add): { securityContext+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } },
                '#withDrop':: d.fn(help='"Removed capabilities"', args=[d.arg(name='drop', type=d.T.array)]),
                withDrop(drop): { securityContext+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } },
                '#withDropMixin':: d.fn(help='"Removed capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
                withDropMixin(drop): { securityContext+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } },
              },
              '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to the container.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."'),
              seLinuxOptions: {
                '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
                withLevel(level): { securityContext+: { seLinuxOptions+: { level: level } } },
                '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
                withRole(role): { securityContext+: { seLinuxOptions+: { role: role } } },
                '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { securityContext+: { seLinuxOptions+: { type: type } } },
                '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
                withUser(user): { securityContext+: { seLinuxOptions+: { user: user } } },
              },
              '#seccompProfile':: d.obj(help='"The seccomp options to use by this container. If seccomp options are\\nprovided at both the pod & container level, the container options\\noverride the pod options.\\nNote that this field cannot be set when spec.os.name is windows."'),
              seccompProfile: {
                '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
                withLocalhostProfile(localhostProfile): { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } },
                '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { securityContext+: { seccompProfile+: { type: type } } },
              },
              '#windowsOptions':: d.obj(help='"The Windows specific settings applied to all containers.\\nIf unspecified, the options from the PodSecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux."'),
              windowsOptions: {
                '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
                withGmsaCredentialSpec(gmsaCredentialSpec): { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } },
                '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
                withGmsaCredentialSpecName(gmsaCredentialSpecName): { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } },
                '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
                withHostProcess(hostProcess): { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } },
                '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
                withRunAsUserName(runAsUserName): { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } },
              },
              '#withAllowPrivilegeEscalation':: d.fn(help='"AllowPrivilegeEscalation controls whether a process can gain more\\nprivileges than its parent process. This bool directly controls if\\nthe no_new_privs flag will be set on the container process.\\nAllowPrivilegeEscalation is true always when the container is:\\n1) run as Privileged\\n2) has CAP_SYS_ADMIN\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='allowPrivilegeEscalation', type=d.T.boolean)]),
              withAllowPrivilegeEscalation(allowPrivilegeEscalation): { securityContext+: { allowPrivilegeEscalation: allowPrivilegeEscalation } },
              '#withPrivileged':: d.fn(help='"Run container in privileged mode.\\nProcesses in privileged containers are essentially equivalent to root on the host.\\nDefaults to false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='privileged', type=d.T.boolean)]),
              withPrivileged(privileged): { securityContext+: { privileged: privileged } },
              '#withProcMount':: d.fn(help='"procMount denotes the type of proc mount to use for the containers.\\nThe default value is Default which uses the container runtime defaults for\\nreadonly paths and masked paths.\\nThis requires the ProcMountType feature flag to be enabled.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='procMount', type=d.T.string)]),
              withProcMount(procMount): { securityContext+: { procMount: procMount } },
              '#withReadOnlyRootFilesystem':: d.fn(help='"Whether this container has a read-only root filesystem.\\nDefault is false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='readOnlyRootFilesystem', type=d.T.boolean)]),
              withReadOnlyRootFilesystem(readOnlyRootFilesystem): { securityContext+: { readOnlyRootFilesystem: readOnlyRootFilesystem } },
              '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
              withRunAsGroup(runAsGroup): { securityContext+: { runAsGroup: runAsGroup } },
              '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
              withRunAsNonRoot(runAsNonRoot): { securityContext+: { runAsNonRoot: runAsNonRoot } },
              '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
              withRunAsUser(runAsUser): { securityContext+: { runAsUser: runAsUser } },
            },
            '#withEnv':: d.fn(help='"EnvVars specifies the environment variables for the profile."', args=[d.arg(name='env', type=d.T.array)]),
            withEnv(env): { env: if std.isArray(v=env) then env else [env] },
            '#withEnvMixin':: d.fn(help='"EnvVars specifies the environment variables for the profile."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
            withEnvMixin(env): { env+: if std.isArray(v=env) then env else [env] },
          },
          '#selectors':: d.obj(help='"Selectors define the pod selector for sidecar injection. Only one rule is supported."'),
          selectors: {
            '#namespaceSelector':: d.obj(help='"NamespaceSelector specifies the label selector for namespaces."'),
            namespaceSelector: {
              '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
              matchExpressions: {
                '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
              '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
            },
            '#objectSelector':: d.obj(help='"ObjectSelector specifies the label selector for objects."'),
            objectSelector: {
              '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
              matchExpressions: {
                '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressions(matchExpressions): { objectSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressionsMixin(matchExpressions): { objectSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabels(matchLabels): { objectSelector+: { matchLabels: matchLabels } },
              '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabelsMixin(matchLabels): { objectSelector+: { matchLabels+: matchLabels } },
            },
          },
          '#withClusterAgentCommunicationEnabled':: d.fn(help='"ClusterAgentCommunicationEnabled enables communication between Agent sidecars and the Cluster Agent.\\nDefault : true"', args=[d.arg(name='clusterAgentCommunicationEnabled', type=d.T.boolean)]),
          withClusterAgentCommunicationEnabled(clusterAgentCommunicationEnabled): { spec+: { features+: { admissionController+: { agentSidecarInjection+: { clusterAgentCommunicationEnabled: clusterAgentCommunicationEnabled } } } } },
          '#withEnabled':: d.fn(help='"Enabled enables Sidecar injections.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { admissionController+: { agentSidecarInjection+: { enabled: enabled } } } } },
          '#withProfiles':: d.fn(help='"Profiles define the sidecar configuration override. Only one profile is supported."', args=[d.arg(name='profiles', type=d.T.array)]),
          withProfiles(profiles): { spec+: { features+: { admissionController+: { agentSidecarInjection+: { profiles: if std.isArray(v=profiles) then profiles else [profiles] } } } } },
          '#withProfilesMixin':: d.fn(help='"Profiles define the sidecar configuration override. Only one profile is supported."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='profiles', type=d.T.array)]),
          withProfilesMixin(profiles): { spec+: { features+: { admissionController+: { agentSidecarInjection+: { profiles+: if std.isArray(v=profiles) then profiles else [profiles] } } } } },
          '#withProvider':: d.fn(help='"Provider is used to add infrastructure provider-specific configurations to the Agent sidecar.\\nCurrently only \\"fargate\\" is supported.\\nTo use the feature in other environments (including local testing) omit the config.\\nSee also: https://docs.datadoghq.com/integrations/eks_fargate"', args=[d.arg(name='provider', type=d.T.string)]),
          withProvider(provider): { spec+: { features+: { admissionController+: { agentSidecarInjection+: { provider: provider } } } } },
          '#withRegistry':: d.fn(help='"Registry overrides the default registry for the sidecar Agent."', args=[d.arg(name='registry', type=d.T.string)]),
          withRegistry(registry): { spec+: { features+: { admissionController+: { agentSidecarInjection+: { registry: registry } } } } },
          '#withSelectors':: d.fn(help='"Selectors define the pod selector for sidecar injection. Only one rule is supported."', args=[d.arg(name='selectors', type=d.T.array)]),
          withSelectors(selectors): { spec+: { features+: { admissionController+: { agentSidecarInjection+: { selectors: if std.isArray(v=selectors) then selectors else [selectors] } } } } },
          '#withSelectorsMixin':: d.fn(help='"Selectors define the pod selector for sidecar injection. Only one rule is supported."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='selectors', type=d.T.array)]),
          withSelectorsMixin(selectors): { spec+: { features+: { admissionController+: { agentSidecarInjection+: { selectors+: if std.isArray(v=selectors) then selectors else [selectors] } } } } },
        },
        '#cwsInstrumentation':: d.obj(help='"CWSInstrumentation holds the CWS Instrumentation endpoint configuration"'),
        cwsInstrumentation: {
          '#withEnabled':: d.fn(help='"Enable the CWS Instrumentation admission controller endpoint.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { admissionController+: { cwsInstrumentation+: { enabled: enabled } } } } },
          '#withMode':: d.fn(help='"Mode defines the behavior of the CWS Instrumentation endpoint, and can be either \\"init_container\\" or \\"remote_copy\\".\\nDefault: \\"remote_copy\\', args=[d.arg(name='mode', type=d.T.string)]),
          withMode(mode): { spec+: { features+: { admissionController+: { cwsInstrumentation+: { mode: mode } } } } },
        },
        '#kubernetesAdmissionEvents':: d.obj(help='"KubernetesAdmissionEvents holds the Kubernetes Admission Events configuration."'),
        kubernetesAdmissionEvents: {
          '#withEnabled':: d.fn(help='"Enable the Kubernetes Admission Events feature.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { admissionController+: { kubernetesAdmissionEvents+: { enabled: enabled } } } } },
        },
        '#mutation':: d.obj(help='"Mutation contains Admission Controller mutation configurations."'),
        mutation: {
          '#withEnabled':: d.fn(help='"Enabled enables the Admission Controller mutation webhook.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { admissionController+: { mutation+: { enabled: enabled } } } } },
        },
        '#validation':: d.obj(help='"Validation contains Admission Controller validation configurations."'),
        validation: {
          '#withEnabled':: d.fn(help='"Enabled enables the Admission Controller validation webhook.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { admissionController+: { validation+: { enabled: enabled } } } } },
        },
        '#withAgentCommunicationMode':: d.fn(help='"AgentCommunicationMode corresponds to the mode used by the Datadog application libraries to communicate with the Agent.\\nIt can be \\"hostip\\", \\"service\\", or \\"socket\\"."', args=[d.arg(name='agentCommunicationMode', type=d.T.string)]),
        withAgentCommunicationMode(agentCommunicationMode): { spec+: { features+: { admissionController+: { agentCommunicationMode: agentCommunicationMode } } } },
        '#withEnabled':: d.fn(help='"Enabled enables the Admission Controller.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { admissionController+: { enabled: enabled } } } },
        '#withFailurePolicy':: d.fn(help='"FailurePolicy determines how unrecognized and timeout errors are handled."', args=[d.arg(name='failurePolicy', type=d.T.string)]),
        withFailurePolicy(failurePolicy): { spec+: { features+: { admissionController+: { failurePolicy: failurePolicy } } } },
        '#withMutateUnlabelled':: d.fn(help="\"MutateUnlabelled enables config injection without the need of pod label 'admission.datadoghq.com/enabled=\\\"true\\\"'.\\nDefault: false\"", args=[d.arg(name='mutateUnlabelled', type=d.T.boolean)]),
        withMutateUnlabelled(mutateUnlabelled): { spec+: { features+: { admissionController+: { mutateUnlabelled: mutateUnlabelled } } } },
        '#withRegistry':: d.fn(help='"Registry defines an image registry for the admission controller."', args=[d.arg(name='registry', type=d.T.string)]),
        withRegistry(registry): { spec+: { features+: { admissionController+: { registry: registry } } } },
        '#withServiceName':: d.fn(help='"ServiceName corresponds to the webhook service name."', args=[d.arg(name='serviceName', type=d.T.string)]),
        withServiceName(serviceName): { spec+: { features+: { admissionController+: { serviceName: serviceName } } } },
        '#withWebhookName':: d.fn(help='"WebhookName is a custom name for the MutatingWebhookConfiguration.\\nDefault: \\"datadog-webhook\\', args=[d.arg(name='webhookName', type=d.T.string)]),
        withWebhookName(webhookName): { spec+: { features+: { admissionController+: { webhookName: webhookName } } } },
      },
      '#apm':: d.obj(help='"APM (Application Performance Monitoring) configuration."'),
      apm: {
        '#errorTrackingStandalone':: d.obj(help='"ErrorTrackingStandalone contains the configuration for the Error Tracking standalone feature.\\nFeature is in preview."'),
        errorTrackingStandalone: {
          '#withEnabled':: d.fn(help='"Enables Error Tracking for backend services.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { apm+: { errorTrackingStandalone+: { enabled: enabled } } } } },
        },
        '#hostPortConfig':: d.obj(help='"HostPortConfig contains host port configuration.\\nEnabled Default: false\\nPort Default: 8126"'),
        hostPortConfig: {
          '#withEnabled':: d.fn(help='"Enabled enables host port configuration"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { apm+: { hostPortConfig+: { enabled: enabled } } } } },
          '#withHostPort':: d.fn(help='"Port takes a port number (0 < x < 65536) to expose on the host. (Most containers do not need this.)\\nIf HostNetwork is enabled, this value must match the ContainerPort."', args=[d.arg(name='hostPort', type=d.T.integer)]),
          withHostPort(hostPort): { spec+: { features+: { apm+: { hostPortConfig+: { hostPort: hostPort } } } } },
        },
        '#instrumentation':: d.obj(help='"SingleStepInstrumentation allows the agent to inject the Datadog APM libraries into all pods in the cluster.\\nFeature is in beta.\\nSee also: https://docs.datadoghq.com/tracing/trace_collection/single-step-apm\\nEnabled Default: false"'),
        instrumentation: {
          '#injector':: d.obj(help='"Injector configures the APM Injector."'),
          injector: {
            '#withImageTag':: d.fn(help='"Set the image tag to use for the APM Injector.\\n(Requires Cluster Agent 7.57.0+)"', args=[d.arg(name='imageTag', type=d.T.string)]),
            withImageTag(imageTag): { spec+: { features+: { apm+: { instrumentation+: { injector+: { imageTag: imageTag } } } } } },
          },
          '#languageDetection':: d.obj(help='"LanguageDetection detects languages and adds them as annotations on Deployments, but does not use these languages for injecting libraries to workload pods.\\n(Requires Agent 7.52.0+ and Cluster Agent 7.52.0+)"'),
          languageDetection: {
            '#withEnabled':: d.fn(help='"Enabled enables Language Detection to automatically detect languages of user workloads (beta).\\nRequires SingleStepInstrumentation.Enabled to be true.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
            withEnabled(enabled): { spec+: { features+: { apm+: { instrumentation+: { languageDetection+: { enabled: enabled } } } } } },
          },
          '#targets':: d.obj(help='"Targets is a list of targets to apply the auto instrumentation to. The first target that matches the pod will be\\nused. If no target matches, the auto instrumentation will not be applied.\\n(Requires Cluster Agent 7.64.0+)"'),
          targets: {
            '#ddTraceConfigs':: d.obj(help='"TracerConfigs is a list of configuration options to use for the installed tracers. These options will be added\\nas environment variables in addition to the injected tracer."'),
            ddTraceConfigs: {
              '#valueFrom':: d.obj(help="\"Source for the environment variable's value. Cannot be used if value is not empty.\""),
              valueFrom: {
                '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
                configMapKeyRef: {
                  '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { valueFrom+: { configMapKeyRef+: { key: key } } },
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { valueFrom+: { configMapKeyRef+: { name: name } } },
                  '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                  withOptional(optional): { valueFrom+: { configMapKeyRef+: { optional: optional } } },
                },
                '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
                fieldRef: {
                  '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                  withApiVersion(apiVersion): { valueFrom+: { fieldRef+: { apiVersion: apiVersion } } },
                  '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                  withFieldPath(fieldPath): { valueFrom+: { fieldRef+: { fieldPath: fieldPath } } },
                },
                '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
                resourceFieldRef: {
                  '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                  withContainerName(containerName): { valueFrom+: { resourceFieldRef+: { containerName: containerName } } },
                  '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                  withDivisor(divisor): { valueFrom+: { resourceFieldRef+: { divisor: divisor } } },
                  '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                  withResource(resource): { valueFrom+: { resourceFieldRef+: { resource: resource } } },
                },
                '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
                secretKeyRef: {
                  '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { valueFrom+: { secretKeyRef+: { key: key } } },
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { valueFrom+: { secretKeyRef+: { name: name } } },
                  '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                  withOptional(optional): { valueFrom+: { secretKeyRef+: { optional: optional } } },
                },
              },
              '#withName':: d.fn(help='"Name of the environment variable. Must be a C_IDENTIFIER."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#namespaceSelector':: d.obj(help='"NamespaceSelector is the namespace selector to match the namespaces to apply the auto instrumentation to. It will\\nbe used in conjunction with the Selector to match the pods."'),
            namespaceSelector: {
              '#matchExpressions':: d.obj(help='"MatchExpressions is a list of label selector requirements to match the labels of the namespace. The labels and\\nexpressions are ANDed. This cannot be used with MatchNames."'),
              matchExpressions: {
                '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#withMatchExpressions':: d.fn(help='"MatchExpressions is a list of label selector requirements to match the labels of the namespace. The labels and\\nexpressions are ANDed. This cannot be used with MatchNames."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchExpressionsMixin':: d.fn(help='"MatchExpressions is a list of label selector requirements to match the labels of the namespace. The labels and\\nexpressions are ANDed. This cannot be used with MatchNames."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchLabels':: d.fn(help='"MatchLabels is a map of key-value pairs to match the labels of the namespace. The labels and expressions are\\nANDed. This cannot be used with MatchNames."', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
              '#withMatchLabelsMixin':: d.fn(help='"MatchLabels is a map of key-value pairs to match the labels of the namespace. The labels and expressions are\\nANDed. This cannot be used with MatchNames."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
              '#withMatchNames':: d.fn(help='"MatchNames is a list of namespace names to match. If empty, all namespaces are matched."', args=[d.arg(name='matchNames', type=d.T.array)]),
              withMatchNames(matchNames): { namespaceSelector+: { matchNames: if std.isArray(v=matchNames) then matchNames else [matchNames] } },
              '#withMatchNamesMixin':: d.fn(help='"MatchNames is a list of namespace names to match. If empty, all namespaces are matched."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchNames', type=d.T.array)]),
              withMatchNamesMixin(matchNames): { namespaceSelector+: { matchNames+: if std.isArray(v=matchNames) then matchNames else [matchNames] } },
            },
            '#podSelector':: d.obj(help='"PodSelector is the pod selector to match the pods to apply the auto instrumentation to. It will be used in\\nconjunction with the NamespaceSelector to match the pods."'),
            podSelector: {
              '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
              matchExpressions: {
                '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressions(matchExpressions): { podSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressionsMixin(matchExpressions): { podSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabels(matchLabels): { podSelector+: { matchLabels: matchLabels } },
              '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabelsMixin(matchLabels): { podSelector+: { matchLabels+: matchLabels } },
            },
            '#withDdTraceConfigs':: d.fn(help='"TracerConfigs is a list of configuration options to use for the installed tracers. These options will be added\\nas environment variables in addition to the injected tracer."', args=[d.arg(name='ddTraceConfigs', type=d.T.array)]),
            withDdTraceConfigs(ddTraceConfigs): { ddTraceConfigs: if std.isArray(v=ddTraceConfigs) then ddTraceConfigs else [ddTraceConfigs] },
            '#withDdTraceConfigsMixin':: d.fn(help='"TracerConfigs is a list of configuration options to use for the installed tracers. These options will be added\\nas environment variables in addition to the injected tracer."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ddTraceConfigs', type=d.T.array)]),
            withDdTraceConfigsMixin(ddTraceConfigs): { ddTraceConfigs+: if std.isArray(v=ddTraceConfigs) then ddTraceConfigs else [ddTraceConfigs] },
            '#withDdTraceVersions':: d.fn(help='"TracerVersions is a map of tracer versions to inject for workloads that match the target. The key is the tracer\\nname and the value is the version to inject."', args=[d.arg(name='ddTraceVersions', type=d.T.object)]),
            withDdTraceVersions(ddTraceVersions): { ddTraceVersions: ddTraceVersions },
            '#withDdTraceVersionsMixin':: d.fn(help='"TracerVersions is a map of tracer versions to inject for workloads that match the target. The key is the tracer\\nname and the value is the version to inject."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ddTraceVersions', type=d.T.object)]),
            withDdTraceVersionsMixin(ddTraceVersions): { ddTraceVersions+: ddTraceVersions },
            '#withName':: d.fn(help='"Name is the name of the target. It will be appended to the pod annotations to identify the target that was used."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
          },
          '#withDisabledNamespaces':: d.fn(help='"DisabledNamespaces disables injecting the Datadog APM libraries into pods in specific namespaces."', args=[d.arg(name='disabledNamespaces', type=d.T.array)]),
          withDisabledNamespaces(disabledNamespaces): { spec+: { features+: { apm+: { instrumentation+: { disabledNamespaces: if std.isArray(v=disabledNamespaces) then disabledNamespaces else [disabledNamespaces] } } } } },
          '#withDisabledNamespacesMixin':: d.fn(help='"DisabledNamespaces disables injecting the Datadog APM libraries into pods in specific namespaces."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='disabledNamespaces', type=d.T.array)]),
          withDisabledNamespacesMixin(disabledNamespaces): { spec+: { features+: { apm+: { instrumentation+: { disabledNamespaces+: if std.isArray(v=disabledNamespaces) then disabledNamespaces else [disabledNamespaces] } } } } },
          '#withEnabled':: d.fn(help='"Enabled enables injecting the Datadog APM libraries into all pods in the cluster.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { apm+: { instrumentation+: { enabled: enabled } } } } },
          '#withEnabledNamespaces':: d.fn(help='"EnabledNamespaces enables injecting the Datadog APM libraries into pods in specific namespaces."', args=[d.arg(name='enabledNamespaces', type=d.T.array)]),
          withEnabledNamespaces(enabledNamespaces): { spec+: { features+: { apm+: { instrumentation+: { enabledNamespaces: if std.isArray(v=enabledNamespaces) then enabledNamespaces else [enabledNamespaces] } } } } },
          '#withEnabledNamespacesMixin':: d.fn(help='"EnabledNamespaces enables injecting the Datadog APM libraries into pods in specific namespaces."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='enabledNamespaces', type=d.T.array)]),
          withEnabledNamespacesMixin(enabledNamespaces): { spec+: { features+: { apm+: { instrumentation+: { enabledNamespaces+: if std.isArray(v=enabledNamespaces) then enabledNamespaces else [enabledNamespaces] } } } } },
          '#withLibVersions':: d.fn(help='"LibVersions configures injection of specific tracing library versions with Single Step Instrumentation.\\n<Library>: <Version>\\nex: \\"java\\": \\"v1.18.0\\', args=[d.arg(name='libVersions', type=d.T.object)]),
          withLibVersions(libVersions): { spec+: { features+: { apm+: { instrumentation+: { libVersions: libVersions } } } } },
          '#withLibVersionsMixin':: d.fn(help='"LibVersions configures injection of specific tracing library versions with Single Step Instrumentation.\\n<Library>: <Version>\\nex: \\"java\\": \\"v1.18.0\\\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='libVersions', type=d.T.object)]),
          withLibVersionsMixin(libVersions): { spec+: { features+: { apm+: { instrumentation+: { libVersions+: libVersions } } } } },
          '#withTargets':: d.fn(help='"Targets is a list of targets to apply the auto instrumentation to. The first target that matches the pod will be\\nused. If no target matches, the auto instrumentation will not be applied.\\n(Requires Cluster Agent 7.64.0+)"', args=[d.arg(name='targets', type=d.T.array)]),
          withTargets(targets): { spec+: { features+: { apm+: { instrumentation+: { targets: if std.isArray(v=targets) then targets else [targets] } } } } },
          '#withTargetsMixin':: d.fn(help='"Targets is a list of targets to apply the auto instrumentation to. The first target that matches the pod will be\\nused. If no target matches, the auto instrumentation will not be applied.\\n(Requires Cluster Agent 7.64.0+)"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='targets', type=d.T.array)]),
          withTargetsMixin(targets): { spec+: { features+: { apm+: { instrumentation+: { targets+: if std.isArray(v=targets) then targets else [targets] } } } } },
        },
        '#unixDomainSocketConfig':: d.obj(help='"UnixDomainSocketConfig contains socket configuration.\\nSee also: https://docs.datadoghq.com/agent/kubernetes/apm/?tab=helm#agent-environment-variables\\nEnabled Default: true\\nPath Default: `/var/run/datadog/apm.socket`"'),
        unixDomainSocketConfig: {
          '#withEnabled':: d.fn(help='"Enabled enables Unix Domain Socket.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { apm+: { unixDomainSocketConfig+: { enabled: enabled } } } } },
          '#withPath':: d.fn(help='"Path defines the socket path used when enabled."', args=[d.arg(name='path', type=d.T.string)]),
          withPath(path): { spec+: { features+: { apm+: { unixDomainSocketConfig+: { path: path } } } } },
        },
        '#withEnabled':: d.fn(help='"Enabled enables Application Performance Monitoring.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { apm+: { enabled: enabled } } } },
      },
      '#asm':: d.obj(help='"ASM (Application Security Management) configuration."'),
      asm: {
        '#iast':: d.obj(help='"IAST configures Interactive Application Security Testing.\\nEnabled Default: false"'),
        iast: {
          '#withEnabled':: d.fn(help='"Enabled enables Interactive Application Security Testing (IAST).\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { asm+: { iast+: { enabled: enabled } } } } },
        },
        '#sca':: d.obj(help='"SCA configures Software Composition Analysis.\\nEnabled Default: false"'),
        sca: {
          '#withEnabled':: d.fn(help='"Enabled enables Software Composition Analysis (SCA).\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { asm+: { sca+: { enabled: enabled } } } } },
        },
        '#threats':: d.obj(help='"Threats configures ASM App & API Protection.\\nEnabled Default: false"'),
        threats: {
          '#withEnabled':: d.fn(help='"Enabled enables ASM App & API Protection.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { asm+: { threats+: { enabled: enabled } } } } },
        },
      },
      '#autoscaling':: d.obj(help='"Autoscaling configuration."'),
      autoscaling: {
        '#cluster':: d.obj(help='"Cluster contains the configuration for the cluster autoscaling product."'),
        cluster: {
          '#withEnabled':: d.fn(help='"Enabled enables the cluster autoscaling product.\\n(Requires Cluster Agent 7.74.0+)\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { autoscaling+: { cluster+: { enabled: enabled } } } } },
        },
        '#workload':: d.obj(help='"Workload contains the configuration for the workload autoscaling product."'),
        workload: {
          '#withEnabled':: d.fn(help='"Enabled enables the workload autoscaling product.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { autoscaling+: { workload+: { enabled: enabled } } } } },
        },
      },
      '#clusterChecks':: d.obj(help='"ClusterChecks configuration."'),
      clusterChecks: {
        '#withEnabled':: d.fn(help='"Enables Cluster Checks scheduling in the Cluster Agent.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { clusterChecks+: { enabled: enabled } } } },
        '#withUseClusterChecksRunners':: d.fn(help='"Enabled enables Cluster Checks Runners to run all Cluster Checks.\\nDefault: false"', args=[d.arg(name='useClusterChecksRunners', type=d.T.boolean)]),
        withUseClusterChecksRunners(useClusterChecksRunners): { spec+: { features+: { clusterChecks+: { useClusterChecksRunners: useClusterChecksRunners } } } },
      },
      '#controlPlaneMonitoring':: d.obj(help='"ControlPlaneMonitoring configuration."'),
      controlPlaneMonitoring: {
        '#withEnabled':: d.fn(help='"Enabled enables control plane monitoring checks in the cluster agent.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { controlPlaneMonitoring+: { enabled: enabled } } } },
      },
      '#cspm':: d.obj(help='"CSPM (Cloud Security Posture Management) configuration."'),
      cspm: {
        '#customBenchmarks':: d.obj(help='"CustomBenchmarks contains CSPM benchmarks.\\nThe content of the ConfigMap will be merged with the benchmarks bundled with the agent.\\nAny benchmarks with the same name as those existing in the agent will take precedence."'),
        customBenchmarks: {
          '#configMap':: d.obj(help='"ConfigMap references an existing ConfigMap with the configuration file content."'),
          configMap: {
            '#items':: d.obj(help='"Items maps a ConfigMap data `key` to a file `path` mount."'),
            items: {
              '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help='"Items maps a ConfigMap data `key` to a file `path` mount."', args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { spec+: { features+: { cspm+: { customBenchmarks+: { configMap+: { items: if std.isArray(v=items) then items else [items] } } } } } },
            '#withItemsMixin':: d.fn(help='"Items maps a ConfigMap data `key` to a file `path` mount."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { spec+: { features+: { cspm+: { customBenchmarks+: { configMap+: { items+: if std.isArray(v=items) then items else [items] } } } } } },
            '#withName':: d.fn(help='"Name is the name of the ConfigMap."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { features+: { cspm+: { customBenchmarks+: { configMap+: { name: name } } } } } },
          },
          '#withConfigData':: d.fn(help='"ConfigData corresponds to the configuration file content."', args=[d.arg(name='configData', type=d.T.string)]),
          withConfigData(configData): { spec+: { features+: { cspm+: { customBenchmarks+: { configData: configData } } } } },
        },
        '#hostBenchmarks':: d.obj(help='"HostBenchmarks contains configuration for host benchmarks."'),
        hostBenchmarks: {
          '#withEnabled':: d.fn(help='"Enabled enables host benchmarks.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { cspm+: { hostBenchmarks+: { enabled: enabled } } } } },
        },
        '#withCheckInterval':: d.fn(help='"CheckInterval defines the check interval."', args=[d.arg(name='checkInterval', type=d.T.string)]),
        withCheckInterval(checkInterval): { spec+: { features+: { cspm+: { checkInterval: checkInterval } } } },
        '#withEnabled':: d.fn(help='"Enabled enables Cloud Security Posture Management.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { cspm+: { enabled: enabled } } } },
      },
      '#cws':: d.obj(help='"CWS (Cloud Workload Security) configuration."'),
      cws: {
        '#customPolicies':: d.obj(help='"CustomPolicies contains security policies.\\nThe content of the ConfigMap will be merged with the policies bundled with the agent.\\nAny policies with the same name as those existing in the agent will take precedence."'),
        customPolicies: {
          '#configMap':: d.obj(help='"ConfigMap references an existing ConfigMap with the configuration file content."'),
          configMap: {
            '#items':: d.obj(help='"Items maps a ConfigMap data `key` to a file `path` mount."'),
            items: {
              '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help='"Items maps a ConfigMap data `key` to a file `path` mount."', args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { spec+: { features+: { cws+: { customPolicies+: { configMap+: { items: if std.isArray(v=items) then items else [items] } } } } } },
            '#withItemsMixin':: d.fn(help='"Items maps a ConfigMap data `key` to a file `path` mount."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { spec+: { features+: { cws+: { customPolicies+: { configMap+: { items+: if std.isArray(v=items) then items else [items] } } } } } },
            '#withName':: d.fn(help='"Name is the name of the ConfigMap."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { features+: { cws+: { customPolicies+: { configMap+: { name: name } } } } } },
          },
          '#withConfigData':: d.fn(help='"ConfigData corresponds to the configuration file content."', args=[d.arg(name='configData', type=d.T.string)]),
          withConfigData(configData): { spec+: { features+: { cws+: { customPolicies+: { configData: configData } } } } },
        },
        '#network':: d.obj(help=''),
        network: {
          '#withEnabled':: d.fn(help='"Enabled enables Cloud Workload Security Network detections.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { cws+: { network+: { enabled: enabled } } } } },
        },
        '#remoteConfiguration':: d.obj(help=''),
        remoteConfiguration: {
          '#withEnabled':: d.fn(help='"Enabled enables Remote Configuration for Cloud Workload Security.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { cws+: { remoteConfiguration+: { enabled: enabled } } } } },
        },
        '#securityProfiles':: d.obj(help=''),
        securityProfiles: {
          '#withEnabled':: d.fn(help='"Enabled enables Security Profiles collection for Cloud Workload Security.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { cws+: { securityProfiles+: { enabled: enabled } } } } },
        },
        '#withDirectSendFromSystemProbe':: d.fn(help='"DirectSendFromSystemProbe configures CWS to send payloads directly from the system-probe, without using the security-agent.\\nThis is an experimental feature. Contact support before using.\\nDefault: false"', args=[d.arg(name='directSendFromSystemProbe', type=d.T.boolean)]),
        withDirectSendFromSystemProbe(directSendFromSystemProbe): { spec+: { features+: { cws+: { directSendFromSystemProbe: directSendFromSystemProbe } } } },
        '#withEnabled':: d.fn(help='"Enabled enables Cloud Workload Security.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { cws+: { enabled: enabled } } } },
        '#withSyscallMonitorEnabled':: d.fn(help='"SyscallMonitorEnabled enables Syscall Monitoring (recommended for troubleshooting only).\\nDefault: false"', args=[d.arg(name='syscallMonitorEnabled', type=d.T.boolean)]),
        withSyscallMonitorEnabled(syscallMonitorEnabled): { spec+: { features+: { cws+: { syscallMonitorEnabled: syscallMonitorEnabled } } } },
      },
      '#dogstatsd':: d.obj(help='"Dogstatsd configuration."'),
      dogstatsd: {
        '#hostPortConfig':: d.obj(help='"HostPortConfig contains host port configuration.\\nEnabled Default: false\\nPort Default: 8125"'),
        hostPortConfig: {
          '#withEnabled':: d.fn(help='"Enabled enables host port configuration"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { dogstatsd+: { hostPortConfig+: { enabled: enabled } } } } },
          '#withHostPort':: d.fn(help='"Port takes a port number (0 < x < 65536) to expose on the host. (Most containers do not need this.)\\nIf HostNetwork is enabled, this value must match the ContainerPort."', args=[d.arg(name='hostPort', type=d.T.integer)]),
          withHostPort(hostPort): { spec+: { features+: { dogstatsd+: { hostPortConfig+: { hostPort: hostPort } } } } },
        },
        '#mapperProfiles':: d.obj(help='"Configure the Dogstasd Mapper Profiles.\\nCan be passed as raw data or via a json encoded string in a config map.\\nSee also: https://docs.datadoghq.com/developers/dogstatsd/dogstatsd_mapper/"'),
        mapperProfiles: {
          '#configMap':: d.obj(help='"ConfigMap references an existing ConfigMap with the configuration file content."'),
          configMap: {
            '#items':: d.obj(help='"Items maps a ConfigMap data `key` to a file `path` mount."'),
            items: {
              '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help='"Items maps a ConfigMap data `key` to a file `path` mount."', args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { spec+: { features+: { dogstatsd+: { mapperProfiles+: { configMap+: { items: if std.isArray(v=items) then items else [items] } } } } } },
            '#withItemsMixin':: d.fn(help='"Items maps a ConfigMap data `key` to a file `path` mount."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { spec+: { features+: { dogstatsd+: { mapperProfiles+: { configMap+: { items+: if std.isArray(v=items) then items else [items] } } } } } },
            '#withName':: d.fn(help='"Name is the name of the ConfigMap."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { features+: { dogstatsd+: { mapperProfiles+: { configMap+: { name: name } } } } } },
          },
          '#withConfigData':: d.fn(help='"ConfigData corresponds to the configuration file content."', args=[d.arg(name='configData', type=d.T.string)]),
          withConfigData(configData): { spec+: { features+: { dogstatsd+: { mapperProfiles+: { configData: configData } } } } },
        },
        '#unixDomainSocketConfig':: d.obj(help='"UnixDomainSocketConfig contains socket configuration.\\nSee also: https://docs.datadoghq.com/agent/kubernetes/apm/?tab=helm#agent-environment-variables\\nEnabled Default: true\\nPath Default: `/var/run/datadog/dsd.socket`"'),
        unixDomainSocketConfig: {
          '#withEnabled':: d.fn(help='"Enabled enables Unix Domain Socket.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { dogstatsd+: { unixDomainSocketConfig+: { enabled: enabled } } } } },
          '#withPath':: d.fn(help='"Path defines the socket path used when enabled."', args=[d.arg(name='path', type=d.T.string)]),
          withPath(path): { spec+: { features+: { dogstatsd+: { unixDomainSocketConfig+: { path: path } } } } },
        },
        '#withNonLocalTraffic':: d.fn(help='"NonLocalTraffic enables non-local traffic for Dogstatsd.\\nDefault: true"', args=[d.arg(name='nonLocalTraffic', type=d.T.boolean)]),
        withNonLocalTraffic(nonLocalTraffic): { spec+: { features+: { dogstatsd+: { nonLocalTraffic: nonLocalTraffic } } } },
        '#withOriginDetectionEnabled':: d.fn(help='"OriginDetectionEnabled enables origin detection for container tagging.\\nSee also: https://docs.datadoghq.com/developers/dogstatsd/unix_socket/#using-origin-detection-for-container-tagging"', args=[d.arg(name='originDetectionEnabled', type=d.T.boolean)]),
        withOriginDetectionEnabled(originDetectionEnabled): { spec+: { features+: { dogstatsd+: { originDetectionEnabled: originDetectionEnabled } } } },
        '#withTagCardinality':: d.fn(help='"TagCardinality configures tag cardinality for the metrics collected using origin detection (`low`, `orchestrator` or `high`).\\nSee also: https://docs.datadoghq.com/getting_started/tagging/assigning_tags/?tab=containerizedenvironments#environment-variables\\nCardinality default: low"', args=[d.arg(name='tagCardinality', type=d.T.string)]),
        withTagCardinality(tagCardinality): { spec+: { features+: { dogstatsd+: { tagCardinality: tagCardinality } } } },
      },
      '#ebpfCheck':: d.obj(help='"EBPFCheck configuration."'),
      ebpfCheck: {
        '#withEnabled':: d.fn(help='"Enables the eBPF check.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { ebpfCheck+: { enabled: enabled } } } },
      },
      '#eventCollection':: d.obj(help='"EventCollection configuration."'),
      eventCollection: {
        '#collectedEventTypes':: d.obj(help='"CollectedEventTypes defines the list of events to collect when UnbundleEvents is enabled.\\nDefault:\\n[\\n{\\"kind\\":\\"Pod\\",\\"reasons\\":[\\"Failed\\",\\"BackOff\\",\\"Unhealthy\\",\\"FailedScheduling\\",\\"FailedMount\\",\\"FailedAttachVolume\\"]},\\n{\\"kind\\":\\"Node\\",\\"reasons\\":[\\"TerminatingEvictedPod\\",\\"NodeNotReady\\",\\"Rebooted\\",\\"HostPortConflict\\"]},\\n{\\"kind\\":\\"CronJob\\",\\"reasons\\":[\\"SawCompletedJob\\"]}\\n]"'),
        collectedEventTypes: {
          '#withKind':: d.fn(help='"Kind is the kind of event to collect. (ex: Pod, Node, CronJob)"', args=[d.arg(name='kind', type=d.T.string)]),
          withKind(kind): { kind: kind },
          '#withReasons':: d.fn(help='"Reasons is a list of event reasons to collect. (ex: Failed, BackOff, Unhealthy)"', args=[d.arg(name='reasons', type=d.T.array)]),
          withReasons(reasons): { reasons: if std.isArray(v=reasons) then reasons else [reasons] },
          '#withReasonsMixin':: d.fn(help='"Reasons is a list of event reasons to collect. (ex: Failed, BackOff, Unhealthy)"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='reasons', type=d.T.array)]),
          withReasonsMixin(reasons): { reasons+: if std.isArray(v=reasons) then reasons else [reasons] },
        },
        '#withCollectKubernetesEvents':: d.fn(help='"CollectKubernetesEvents enables Kubernetes event collection.\\nDefault: true"', args=[d.arg(name='collectKubernetesEvents', type=d.T.boolean)]),
        withCollectKubernetesEvents(collectKubernetesEvents): { spec+: { features+: { eventCollection+: { collectKubernetesEvents: collectKubernetesEvents } } } },
        '#withCollectedEventTypes':: d.fn(help='"CollectedEventTypes defines the list of events to collect when UnbundleEvents is enabled.\\nDefault:\\n[\\n{\\"kind\\":\\"Pod\\",\\"reasons\\":[\\"Failed\\",\\"BackOff\\",\\"Unhealthy\\",\\"FailedScheduling\\",\\"FailedMount\\",\\"FailedAttachVolume\\"]},\\n{\\"kind\\":\\"Node\\",\\"reasons\\":[\\"TerminatingEvictedPod\\",\\"NodeNotReady\\",\\"Rebooted\\",\\"HostPortConflict\\"]},\\n{\\"kind\\":\\"CronJob\\",\\"reasons\\":[\\"SawCompletedJob\\"]}\\n]"', args=[d.arg(name='collectedEventTypes', type=d.T.array)]),
        withCollectedEventTypes(collectedEventTypes): { spec+: { features+: { eventCollection+: { collectedEventTypes: if std.isArray(v=collectedEventTypes) then collectedEventTypes else [collectedEventTypes] } } } },
        '#withCollectedEventTypesMixin':: d.fn(help='"CollectedEventTypes defines the list of events to collect when UnbundleEvents is enabled.\\nDefault:\\n[\\n{\\"kind\\":\\"Pod\\",\\"reasons\\":[\\"Failed\\",\\"BackOff\\",\\"Unhealthy\\",\\"FailedScheduling\\",\\"FailedMount\\",\\"FailedAttachVolume\\"]},\\n{\\"kind\\":\\"Node\\",\\"reasons\\":[\\"TerminatingEvictedPod\\",\\"NodeNotReady\\",\\"Rebooted\\",\\"HostPortConflict\\"]},\\n{\\"kind\\":\\"CronJob\\",\\"reasons\\":[\\"SawCompletedJob\\"]}\\n]"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='collectedEventTypes', type=d.T.array)]),
        withCollectedEventTypesMixin(collectedEventTypes): { spec+: { features+: { eventCollection+: { collectedEventTypes+: if std.isArray(v=collectedEventTypes) then collectedEventTypes else [collectedEventTypes] } } } },
        '#withUnbundleEvents':: d.fn(help='"UnbundleEvents enables collection of Kubernetes events as individual events.\\nDefault: false"', args=[d.arg(name='unbundleEvents', type=d.T.boolean)]),
        withUnbundleEvents(unbundleEvents): { spec+: { features+: { eventCollection+: { unbundleEvents: unbundleEvents } } } },
      },
      '#externalMetricsServer':: d.obj(help='"ExternalMetricsServer configuration."'),
      externalMetricsServer: {
        '#endpoint':: d.obj(help='"Override the API endpoint for the External Metrics Server.\\nURL Default: \\"https://app.datadoghq.com\\"."'),
        endpoint: {
          '#credentials':: d.obj(help='"Credentials defines the Datadog credentials used to submit data to/query data from Datadog."'),
          credentials: {
            '#apiSecret':: d.obj(help='"APISecret references an existing Secret which stores the API key instead of creating a new one.\\nIf set, this parameter takes precedence over \\"APIKey\\"."'),
            apiSecret: {
              '#withKeyName':: d.fn(help='"KeyName is the key of the secret to use."', args=[d.arg(name='keyName', type=d.T.string)]),
              withKeyName(keyName): { spec+: { features+: { externalMetricsServer+: { endpoint+: { credentials+: { apiSecret+: { keyName: keyName } } } } } } },
              '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
              withSecretName(secretName): { spec+: { features+: { externalMetricsServer+: { endpoint+: { credentials+: { apiSecret+: { secretName: secretName } } } } } } },
            },
            '#appSecret':: d.obj(help='"AppSecret references an existing Secret which stores the application key instead of creating a new one.\\nIf set, this parameter takes precedence over \\"AppKey\\"."'),
            appSecret: {
              '#withKeyName':: d.fn(help='"KeyName is the key of the secret to use."', args=[d.arg(name='keyName', type=d.T.string)]),
              withKeyName(keyName): { spec+: { features+: { externalMetricsServer+: { endpoint+: { credentials+: { appSecret+: { keyName: keyName } } } } } } },
              '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
              withSecretName(secretName): { spec+: { features+: { externalMetricsServer+: { endpoint+: { credentials+: { appSecret+: { secretName: secretName } } } } } } },
            },
            '#withApiKey':: d.fn(help='"APIKey configures your Datadog API key.\\nSee also: https://app.datadoghq.com/account/settings#agent/kubernetes"', args=[d.arg(name='apiKey', type=d.T.string)]),
            withApiKey(apiKey): { spec+: { features+: { externalMetricsServer+: { endpoint+: { credentials+: { apiKey: apiKey } } } } } },
            '#withAppKey':: d.fn(help='"AppKey configures your Datadog application key.\\nIf you are using features.externalMetricsServer.enabled = true, you must set\\na Datadog application key for read access to your metrics."', args=[d.arg(name='appKey', type=d.T.string)]),
            withAppKey(appKey): { spec+: { features+: { externalMetricsServer+: { endpoint+: { credentials+: { appKey: appKey } } } } } },
          },
          '#withUrl':: d.fn(help='"URL defines the endpoint URL."', args=[d.arg(name='url', type=d.T.string)]),
          withUrl(url): { spec+: { features+: { externalMetricsServer+: { endpoint+: { url: url } } } } },
        },
        '#withEnabled':: d.fn(help='"Enabled enables the External Metrics Server.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { externalMetricsServer+: { enabled: enabled } } } },
        '#withPort':: d.fn(help='"Port specifies the metricsProvider External Metrics Server service port.\\nDefault: 8443"', args=[d.arg(name='port', type=d.T.integer)]),
        withPort(port): { spec+: { features+: { externalMetricsServer+: { port: port } } } },
        '#withRegisterAPIService':: d.fn(help='"RegisterAPIService registers the External Metrics endpoint as an APIService\\nDefault: true"', args=[d.arg(name='registerAPIService', type=d.T.boolean)]),
        withRegisterAPIService(registerAPIService): { spec+: { features+: { externalMetricsServer+: { registerAPIService: registerAPIService } } } },
        '#withUseDatadogMetrics':: d.fn(help='"UseDatadogMetrics enables usage of the DatadogMetrics CRD (allowing one to scale on arbitrary Datadog metric queries).\\nDefault: true"', args=[d.arg(name='useDatadogMetrics', type=d.T.boolean)]),
        withUseDatadogMetrics(useDatadogMetrics): { spec+: { features+: { externalMetricsServer+: { useDatadogMetrics: useDatadogMetrics } } } },
        '#withWpaController':: d.fn(help='"WPAController enables the informer and controller of the Watermark Pod Autoscaler.\\nNOTE: The Watermark Pod Autoscaler controller needs to be installed.\\nSee also: https://github.com/DataDog/watermarkpodautoscaler.\\nDefault: false"', args=[d.arg(name='wpaController', type=d.T.boolean)]),
        withWpaController(wpaController): { spec+: { features+: { externalMetricsServer+: { wpaController: wpaController } } } },
      },
      '#gpu':: d.obj(help='"GPU monitoring"'),
      gpu: {
        '#withEnabled':: d.fn(help='"Enabled enables GPU monitoring core check.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { gpu+: { enabled: enabled } } } },
        '#withPatchCgroupPermissions':: d.fn(help='"PatchCgroupPermissions enables the patch of cgroup permissions for GPU monitoring, in case\\nthe container runtime is not properly configured and the Agent containers lose access to GPU devices.\\nDefault: false"', args=[d.arg(name='patchCgroupPermissions', type=d.T.boolean)]),
        withPatchCgroupPermissions(patchCgroupPermissions): { spec+: { features+: { gpu+: { patchCgroupPermissions: patchCgroupPermissions } } } },
        '#withPrivilegedMode':: d.fn(help='"PrivilegedMode enables GPU Probe module in System Probe.\\nDefault: false"', args=[d.arg(name='privilegedMode', type=d.T.boolean)]),
        withPrivilegedMode(privilegedMode): { spec+: { features+: { gpu+: { privilegedMode: privilegedMode } } } },
        '#withRequiredRuntimeClassName':: d.fn(help='"PodRuntimeClassName specifies the runtime class name required for the GPU monitoring feature.\\nIf the value is an empty string, the runtime class is not set.\\nDefault: nvidia"', args=[d.arg(name='requiredRuntimeClassName', type=d.T.string)]),
        withRequiredRuntimeClassName(requiredRuntimeClassName): { spec+: { features+: { gpu+: { requiredRuntimeClassName: requiredRuntimeClassName } } } },
      },
      '#helmCheck':: d.obj(help='"HelmCheck configuration."'),
      helmCheck: {
        '#withCollectEvents':: d.fn(help='"CollectEvents set to `true` enables event collection in the Helm check\\n(Requires Agent 7.36.0+ and Cluster Agent 1.20.0+)\\nDefault: false"', args=[d.arg(name='collectEvents', type=d.T.boolean)]),
        withCollectEvents(collectEvents): { spec+: { features+: { helmCheck+: { collectEvents: collectEvents } } } },
        '#withEnabled':: d.fn(help='"Enabled enables the Helm check.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { helmCheck+: { enabled: enabled } } } },
        '#withValuesAsTags':: d.fn(help='"ValuesAsTags collects Helm values from a release and uses them as tags\\n(Requires Agent and Cluster Agent 7.40.0+).\\nDefault: {}"', args=[d.arg(name='valuesAsTags', type=d.T.object)]),
        withValuesAsTags(valuesAsTags): { spec+: { features+: { helmCheck+: { valuesAsTags: valuesAsTags } } } },
        '#withValuesAsTagsMixin':: d.fn(help='"ValuesAsTags collects Helm values from a release and uses them as tags\\n(Requires Agent and Cluster Agent 7.40.0+).\\nDefault: {}"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='valuesAsTags', type=d.T.object)]),
        withValuesAsTagsMixin(valuesAsTags): { spec+: { features+: { helmCheck+: { valuesAsTags+: valuesAsTags } } } },
      },
      '#kubeStateMetricsCore':: d.obj(help='"KubeStateMetricsCore check configuration."'),
      kubeStateMetricsCore: {
        '#collectCrMetrics':: d.obj(help='"`CollectCrMetrics` defines custom resources for the kube-state-metrics core check to collect.\\n\\nThe datadog agent uses the same logic as upstream `kube-state-metrics`. So is its configuration.\\nThe exact structure and existing fields of each item in this list can be found in:\\nhttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/metrics/extend/customresourcestate-metrics.md"'),
        collectCrMetrics: {
          '#groupVersionKind':: d.obj(help='"GroupVersionKind of the custom resource to be monitored."'),
          groupVersionKind: {
            '#withGroup':: d.fn(help='', args=[d.arg(name='group', type=d.T.string)]),
            withGroup(group): { groupVersionKind+: { group: group } },
            '#withKind':: d.fn(help='', args=[d.arg(name='kind', type=d.T.string)]),
            withKind(kind): { groupVersionKind+: { kind: kind } },
            '#withVersion':: d.fn(help='', args=[d.arg(name='version', type=d.T.string)]),
            withVersion(version): { groupVersionKind+: { version: version } },
          },
          '#metrics':: d.obj(help='"Metrics are the custom resource fields to be collected."'),
          metrics: {
            '#each':: d.obj(help='"Each targets a value or values from the resource."'),
            each: {
              '#gauge':: d.obj(help='"Gauge defines a gauge metric."'),
              gauge: {
                '#withLabelFromKey':: d.fn(help='"LabelFromKey adds a label with the given name if Path is an object. The label value will be the object key."', args=[d.arg(name='labelFromKey', type=d.T.string)]),
                withLabelFromKey(labelFromKey): { each+: { gauge+: { labelFromKey: labelFromKey } } },
                '#withLabelsFromPath':: d.fn(help='"LabelsFromPath adds additional labels where the value of the label is taken from a field under Path."', args=[d.arg(name='labelsFromPath', type=d.T.object)]),
                withLabelsFromPath(labelsFromPath): { each+: { gauge+: { labelsFromPath: labelsFromPath } } },
                '#withLabelsFromPathMixin':: d.fn(help='"LabelsFromPath adds additional labels where the value of the label is taken from a field under Path."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labelsFromPath', type=d.T.object)]),
                withLabelsFromPathMixin(labelsFromPath): { each+: { gauge+: { labelsFromPath+: labelsFromPath } } },
                '#withNilIsZero':: d.fn(help='"NilIsZero indicates that if a value is nil it will be treated as zero value."', args=[d.arg(name='nilIsZero', type=d.T.boolean)]),
                withNilIsZero(nilIsZero): { each+: { gauge+: { nilIsZero: nilIsZero } } },
                '#withPath':: d.fn(help='"Path is the path to to generate metric(s) for."', args=[d.arg(name='path', type=d.T.array)]),
                withPath(path): { each+: { gauge+: { path: if std.isArray(v=path) then path else [path] } } },
                '#withPathMixin':: d.fn(help='"Path is the path to to generate metric(s) for."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='path', type=d.T.array)]),
                withPathMixin(path): { each+: { gauge+: { path+: if std.isArray(v=path) then path else [path] } } },
                '#withValueFrom':: d.fn(help='"ValueFrom is the path to a numeric field under Path that will be the metric value."', args=[d.arg(name='valueFrom', type=d.T.array)]),
                withValueFrom(valueFrom): { each+: { gauge+: { valueFrom: if std.isArray(v=valueFrom) then valueFrom else [valueFrom] } } },
                '#withValueFromMixin':: d.fn(help='"ValueFrom is the path to a numeric field under Path that will be the metric value."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='valueFrom', type=d.T.array)]),
                withValueFromMixin(valueFrom): { each+: { gauge+: { valueFrom+: if std.isArray(v=valueFrom) then valueFrom else [valueFrom] } } },
              },
              '#info':: d.obj(help='"Info defines an info metric."'),
              info: {
                '#withLabelFromKey':: d.fn(help='"LabelFromKey adds a label with the given name if Path is an object. The label value will be the object key."', args=[d.arg(name='labelFromKey', type=d.T.string)]),
                withLabelFromKey(labelFromKey): { each+: { info+: { labelFromKey: labelFromKey } } },
                '#withLabelsFromPath':: d.fn(help='"LabelsFromPath adds additional labels where the value of the label is taken from a field under Path."', args=[d.arg(name='labelsFromPath', type=d.T.object)]),
                withLabelsFromPath(labelsFromPath): { each+: { info+: { labelsFromPath: labelsFromPath } } },
                '#withLabelsFromPathMixin':: d.fn(help='"LabelsFromPath adds additional labels where the value of the label is taken from a field under Path."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labelsFromPath', type=d.T.object)]),
                withLabelsFromPathMixin(labelsFromPath): { each+: { info+: { labelsFromPath+: labelsFromPath } } },
                '#withPath':: d.fn(help='"Path is the path to to generate metric(s) for."', args=[d.arg(name='path', type=d.T.array)]),
                withPath(path): { each+: { info+: { path: if std.isArray(v=path) then path else [path] } } },
                '#withPathMixin':: d.fn(help='"Path is the path to to generate metric(s) for."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='path', type=d.T.array)]),
                withPathMixin(path): { each+: { info+: { path+: if std.isArray(v=path) then path else [path] } } },
              },
              '#stateSet':: d.obj(help='"StateSet defines a state set metric."'),
              stateSet: {
                '#withLabelName':: d.fn(help='"LabelName is the key of the label which is used for each entry in List to expose the value."', args=[d.arg(name='labelName', type=d.T.string)]),
                withLabelName(labelName): { each+: { stateSet+: { labelName: labelName } } },
                '#withLabelsFromPath':: d.fn(help='"LabelsFromPath adds additional labels where the value of the label is taken from a field under Path."', args=[d.arg(name='labelsFromPath', type=d.T.object)]),
                withLabelsFromPath(labelsFromPath): { each+: { stateSet+: { labelsFromPath: labelsFromPath } } },
                '#withLabelsFromPathMixin':: d.fn(help='"LabelsFromPath adds additional labels where the value of the label is taken from a field under Path."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labelsFromPath', type=d.T.object)]),
                withLabelsFromPathMixin(labelsFromPath): { each+: { stateSet+: { labelsFromPath+: labelsFromPath } } },
                '#withList':: d.fn(help='"List is the list of values to expose a value for."', args=[d.arg(name='list', type=d.T.array)]),
                withList(list): { each+: { stateSet+: { list: if std.isArray(v=list) then list else [list] } } },
                '#withListMixin':: d.fn(help='"List is the list of values to expose a value for."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='list', type=d.T.array)]),
                withListMixin(list): { each+: { stateSet+: { list+: if std.isArray(v=list) then list else [list] } } },
                '#withPath':: d.fn(help='"Path is the path to to generate metric(s) for."', args=[d.arg(name='path', type=d.T.array)]),
                withPath(path): { each+: { stateSet+: { path: if std.isArray(v=path) then path else [path] } } },
                '#withPathMixin':: d.fn(help='"Path is the path to to generate metric(s) for."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='path', type=d.T.array)]),
                withPathMixin(path): { each+: { stateSet+: { path+: if std.isArray(v=path) then path else [path] } } },
                '#withValueFrom':: d.fn(help='"ValueFrom is the subpath to compare the list to."', args=[d.arg(name='valueFrom', type=d.T.array)]),
                withValueFrom(valueFrom): { each+: { stateSet+: { valueFrom: if std.isArray(v=valueFrom) then valueFrom else [valueFrom] } } },
                '#withValueFromMixin':: d.fn(help='"ValueFrom is the subpath to compare the list to."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='valueFrom', type=d.T.array)]),
                withValueFromMixin(valueFrom): { each+: { stateSet+: { valueFrom+: if std.isArray(v=valueFrom) then valueFrom else [valueFrom] } } },
              },
              '#withType':: d.fn(help='"Type defines the type of the metric."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { each+: { type: type } },
            },
            '#withCommonLabels':: d.fn(help='"CommonLabels are added to all metrics."', args=[d.arg(name='commonLabels', type=d.T.object)]),
            withCommonLabels(commonLabels): { commonLabels: commonLabels },
            '#withCommonLabelsMixin':: d.fn(help='"CommonLabels are added to all metrics."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='commonLabels', type=d.T.object)]),
            withCommonLabelsMixin(commonLabels): { commonLabels+: commonLabels },
            '#withHelp':: d.fn(help='"Help text for the metric."', args=[d.arg(name='help', type=d.T.string)]),
            withHelp(help): { help: help },
            '#withLabelsFromPath':: d.fn(help='"LabelsFromPath adds additional labels where the value is taken from a field in the resource."', args=[d.arg(name='labelsFromPath', type=d.T.object)]),
            withLabelsFromPath(labelsFromPath): { labelsFromPath: labelsFromPath },
            '#withLabelsFromPathMixin':: d.fn(help='"LabelsFromPath adds additional labels where the value is taken from a field in the resource."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labelsFromPath', type=d.T.object)]),
            withLabelsFromPathMixin(labelsFromPath): { labelsFromPath+: labelsFromPath },
            '#withName':: d.fn(help='"Name of the metric. Subject to prefixing based on the configuration of the Resource."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
          },
          '#withCommonLabels':: d.fn(help='"CommonLabels are added to all metrics."', args=[d.arg(name='commonLabels', type=d.T.object)]),
          withCommonLabels(commonLabels): { commonLabels: commonLabels },
          '#withCommonLabelsMixin':: d.fn(help='"CommonLabels are added to all metrics."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='commonLabels', type=d.T.object)]),
          withCommonLabelsMixin(commonLabels): { commonLabels+: commonLabels },
          '#withLabelsFromPath':: d.fn(help='"LabelsFromPath adds additional labels where the value is taken from a field in the resource."', args=[d.arg(name='labelsFromPath', type=d.T.object)]),
          withLabelsFromPath(labelsFromPath): { labelsFromPath: labelsFromPath },
          '#withLabelsFromPathMixin':: d.fn(help='"LabelsFromPath adds additional labels where the value is taken from a field in the resource."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labelsFromPath', type=d.T.object)]),
          withLabelsFromPathMixin(labelsFromPath): { labelsFromPath+: labelsFromPath },
          '#withMetricNamePrefix':: d.fn(help='"MetricNamePrefix defines a prefix for all metrics of the resource.\\nIf set to \\"\\", no prefix will be added.\\nExample: If set to \\"foo\\", MetricNamePrefix will be \\"foo_<metric>\\"."', args=[d.arg(name='metricNamePrefix', type=d.T.string)]),
          withMetricNamePrefix(metricNamePrefix): { metricNamePrefix: metricNamePrefix },
          '#withMetrics':: d.fn(help='"Metrics are the custom resource fields to be collected."', args=[d.arg(name='metrics', type=d.T.array)]),
          withMetrics(metrics): { metrics: if std.isArray(v=metrics) then metrics else [metrics] },
          '#withMetricsMixin':: d.fn(help='"Metrics are the custom resource fields to be collected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='metrics', type=d.T.array)]),
          withMetricsMixin(metrics): { metrics+: if std.isArray(v=metrics) then metrics else [metrics] },
          '#withResourcePlural':: d.fn(help='"ResourcePlural sets the plural name of the resource. Defaults to the plural version of the Kind according to flect.Pluralize."', args=[d.arg(name='resourcePlural', type=d.T.string)]),
          withResourcePlural(resourcePlural): { resourcePlural: resourcePlural },
        },
        '#conf':: d.obj(help='"Conf overrides the configuration for the default Kubernetes State Metrics Core check.\\nThis must point to a ConfigMap containing a valid cluster check configuration."'),
        conf: {
          '#configMap':: d.obj(help='"ConfigMap references an existing ConfigMap with the configuration file content."'),
          configMap: {
            '#items':: d.obj(help='"Items maps a ConfigMap data `key` to a file `path` mount."'),
            items: {
              '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help='"Items maps a ConfigMap data `key` to a file `path` mount."', args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { spec+: { features+: { kubeStateMetricsCore+: { conf+: { configMap+: { items: if std.isArray(v=items) then items else [items] } } } } } },
            '#withItemsMixin':: d.fn(help='"Items maps a ConfigMap data `key` to a file `path` mount."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { spec+: { features+: { kubeStateMetricsCore+: { conf+: { configMap+: { items+: if std.isArray(v=items) then items else [items] } } } } } },
            '#withName':: d.fn(help='"Name is the name of the ConfigMap."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { features+: { kubeStateMetricsCore+: { conf+: { configMap+: { name: name } } } } } },
          },
          '#withConfigData':: d.fn(help='"ConfigData corresponds to the configuration file content."', args=[d.arg(name='configData', type=d.T.string)]),
          withConfigData(configData): { spec+: { features+: { kubeStateMetricsCore+: { conf+: { configData: configData } } } } },
        },
        '#withCollectCrMetrics':: d.fn(help='"`CollectCrMetrics` defines custom resources for the kube-state-metrics core check to collect.\\n\\nThe datadog agent uses the same logic as upstream `kube-state-metrics`. So is its configuration.\\nThe exact structure and existing fields of each item in this list can be found in:\\nhttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/metrics/extend/customresourcestate-metrics.md"', args=[d.arg(name='collectCrMetrics', type=d.T.array)]),
        withCollectCrMetrics(collectCrMetrics): { spec+: { features+: { kubeStateMetricsCore+: { collectCrMetrics: if std.isArray(v=collectCrMetrics) then collectCrMetrics else [collectCrMetrics] } } } },
        '#withCollectCrMetricsMixin':: d.fn(help='"`CollectCrMetrics` defines custom resources for the kube-state-metrics core check to collect.\\n\\nThe datadog agent uses the same logic as upstream `kube-state-metrics`. So is its configuration.\\nThe exact structure and existing fields of each item in this list can be found in:\\nhttps://github.com/kubernetes/kube-state-metrics/blob/main/docs/metrics/extend/customresourcestate-metrics.md"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='collectCrMetrics', type=d.T.array)]),
        withCollectCrMetricsMixin(collectCrMetrics): { spec+: { features+: { kubeStateMetricsCore+: { collectCrMetrics+: if std.isArray(v=collectCrMetrics) then collectCrMetrics else [collectCrMetrics] } } } },
        '#withEnabled':: d.fn(help='"Enabled enables Kube State Metrics Core.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { kubeStateMetricsCore+: { enabled: enabled } } } },
      },
      '#liveContainerCollection':: d.obj(help='"LiveContainerCollection configuration."'),
      liveContainerCollection: {
        '#withEnabled':: d.fn(help='"Enables container collection for the Live Container View.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { liveContainerCollection+: { enabled: enabled } } } },
      },
      '#liveProcessCollection':: d.obj(help='"LiveProcessCollection configuration."'),
      liveProcessCollection: {
        '#withEnabled':: d.fn(help='"Enabled enables Process monitoring.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { liveProcessCollection+: { enabled: enabled } } } },
        '#withScrubProcessArguments':: d.fn(help='"ScrubProcessArguments enables scrubbing of sensitive data in process command-lines (passwords, tokens, etc. ).\\nDefault: true"', args=[d.arg(name='scrubProcessArguments', type=d.T.boolean)]),
        withScrubProcessArguments(scrubProcessArguments): { spec+: { features+: { liveProcessCollection+: { scrubProcessArguments: scrubProcessArguments } } } },
        '#withStripProcessArguments':: d.fn(help='"StripProcessArguments enables stripping of all process arguments.\\nDefault: false"', args=[d.arg(name='stripProcessArguments', type=d.T.boolean)]),
        withStripProcessArguments(stripProcessArguments): { spec+: { features+: { liveProcessCollection+: { stripProcessArguments: stripProcessArguments } } } },
      },
      '#logCollection':: d.obj(help='"LogCollection configuration."'),
      logCollection: {
        '#withAutoMultiLineDetection':: d.fn(help='"AutoMultiLineDetection allows the Agent to detect and aggregate common multi-line logs automatically.\\nSee also: https://docs.datadoghq.com/agent/logs/auto_multiline_detection/"', args=[d.arg(name='autoMultiLineDetection', type=d.T.boolean)]),
        withAutoMultiLineDetection(autoMultiLineDetection): { spec+: { features+: { logCollection+: { autoMultiLineDetection: autoMultiLineDetection } } } },
        '#withContainerCollectAll':: d.fn(help='"ContainerCollectAll enables Log collection from all containers.\\nDefault: false"', args=[d.arg(name='containerCollectAll', type=d.T.boolean)]),
        withContainerCollectAll(containerCollectAll): { spec+: { features+: { logCollection+: { containerCollectAll: containerCollectAll } } } },
        '#withContainerCollectUsingFiles':: d.fn(help='"ContainerCollectUsingFiles enables log collection from files in `/var/log/pods instead` of using the container runtime API.\\nCollecting logs from files is usually the most efficient way of collecting logs.\\nSee also: https://docs.datadoghq.com/agent/basic_agent_usage/kubernetes/#log-collection-setup\\nDefault: true"', args=[d.arg(name='containerCollectUsingFiles', type=d.T.boolean)]),
        withContainerCollectUsingFiles(containerCollectUsingFiles): { spec+: { features+: { logCollection+: { containerCollectUsingFiles: containerCollectUsingFiles } } } },
        '#withContainerLogsPath':: d.fn(help='"ContainerLogsPath allows log collection from the container log path.\\nSet to a different path if you are not using the Docker runtime.\\nSee also: https://docs.datadoghq.com/agent/kubernetes/daemonset_setup/?tab=k8sfile#create-manifest\\nDefault: `/var/lib/docker/containers`"', args=[d.arg(name='containerLogsPath', type=d.T.string)]),
        withContainerLogsPath(containerLogsPath): { spec+: { features+: { logCollection+: { containerLogsPath: containerLogsPath } } } },
        '#withContainerSymlinksPath':: d.fn(help='"ContainerSymlinksPath allows log collection to use symbolic links in this directory to validate container ID -> pod.\\nDefault: `/var/log/containers`"', args=[d.arg(name='containerSymlinksPath', type=d.T.string)]),
        withContainerSymlinksPath(containerSymlinksPath): { spec+: { features+: { logCollection+: { containerSymlinksPath: containerSymlinksPath } } } },
        '#withEnabled':: d.fn(help='"Enabled enables Log collection.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { logCollection+: { enabled: enabled } } } },
        '#withOpenFilesLimit':: d.fn(help='"OpenFilesLimit sets the maximum number of log files that the Datadog Agent tails.\\nIncreasing this limit can increase resource consumption of the Agent.\\nSee also: https://docs.datadoghq.com/agent/basic_agent_usage/kubernetes/#log-collection-setup\\nDefault: 100"', args=[d.arg(name='openFilesLimit', type=d.T.integer)]),
        withOpenFilesLimit(openFilesLimit): { spec+: { features+: { logCollection+: { openFilesLimit: openFilesLimit } } } },
        '#withPodLogsPath':: d.fn(help='"PodLogsPath allows log collection from a pod log path.\\nDefault: `/var/log/pods`"', args=[d.arg(name='podLogsPath', type=d.T.string)]),
        withPodLogsPath(podLogsPath): { spec+: { features+: { logCollection+: { podLogsPath: podLogsPath } } } },
        '#withTempStoragePath':: d.fn(help='"TempStoragePath (always mounted from the host) is used by the Agent to store information about processed log files.\\nIf the Agent is restarted, it starts tailing the log files immediately.\\nDefault: `/var/lib/datadog-agent/logs`"', args=[d.arg(name='tempStoragePath', type=d.T.string)]),
        withTempStoragePath(tempStoragePath): { spec+: { features+: { logCollection+: { tempStoragePath: tempStoragePath } } } },
      },
      '#npm':: d.obj(help='"NPM (Network Performance Monitoring) configuration."'),
      npm: {
        '#withCollectDNSStats':: d.fn(help='"CollectDNSStats enables DNS stat collection.\\nDefault: false"', args=[d.arg(name='collectDNSStats', type=d.T.boolean)]),
        withCollectDNSStats(collectDNSStats): { spec+: { features+: { npm+: { collectDNSStats: collectDNSStats } } } },
        '#withEnableConntrack':: d.fn(help='"EnableConntrack enables the system-probe agent to connect to the netlink/conntrack subsystem to add NAT information to connection data.\\nSee also: http://conntrack-tools.netfilter.org/\\nDefault: false"', args=[d.arg(name='enableConntrack', type=d.T.boolean)]),
        withEnableConntrack(enableConntrack): { spec+: { features+: { npm+: { enableConntrack: enableConntrack } } } },
        '#withEnabled':: d.fn(help='"Enabled enables Network Performance Monitoring.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { npm+: { enabled: enabled } } } },
      },
      '#oomKill':: d.obj(help='"OOMKill configuration."'),
      oomKill: {
        '#withEnabled':: d.fn(help='"Enables the OOMKill eBPF-based check.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { oomKill+: { enabled: enabled } } } },
      },
      '#orchestratorExplorer':: d.obj(help='"OrchestratorExplorer check configuration."'),
      orchestratorExplorer: {
        '#conf':: d.obj(help='"Conf overrides the configuration for the default Orchestrator Explorer check.\\nThis must point to a ConfigMap containing a valid cluster check configuration."'),
        conf: {
          '#configMap':: d.obj(help='"ConfigMap references an existing ConfigMap with the configuration file content."'),
          configMap: {
            '#items':: d.obj(help='"Items maps a ConfigMap data `key` to a file `path` mount."'),
            items: {
              '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help='"Items maps a ConfigMap data `key` to a file `path` mount."', args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { spec+: { features+: { orchestratorExplorer+: { conf+: { configMap+: { items: if std.isArray(v=items) then items else [items] } } } } } },
            '#withItemsMixin':: d.fn(help='"Items maps a ConfigMap data `key` to a file `path` mount."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { spec+: { features+: { orchestratorExplorer+: { conf+: { configMap+: { items+: if std.isArray(v=items) then items else [items] } } } } } },
            '#withName':: d.fn(help='"Name is the name of the ConfigMap."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { features+: { orchestratorExplorer+: { conf+: { configMap+: { name: name } } } } } },
          },
          '#withConfigData':: d.fn(help='"ConfigData corresponds to the configuration file content."', args=[d.arg(name='configData', type=d.T.string)]),
          withConfigData(configData): { spec+: { features+: { orchestratorExplorer+: { conf+: { configData: configData } } } } },
        },
        '#withCustomResources':: d.fn(help='"`CustomResources` defines custom resources for the orchestrator explorer to collect.\\nEach item should follow the convention `group/version/kind`. For example, `datadoghq.com/v1alpha1/datadogmetrics`."', args=[d.arg(name='customResources', type=d.T.array)]),
        withCustomResources(customResources): { spec+: { features+: { orchestratorExplorer+: { customResources: if std.isArray(v=customResources) then customResources else [customResources] } } } },
        '#withCustomResourcesMixin':: d.fn(help='"`CustomResources` defines custom resources for the orchestrator explorer to collect.\\nEach item should follow the convention `group/version/kind`. For example, `datadoghq.com/v1alpha1/datadogmetrics`."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='customResources', type=d.T.array)]),
        withCustomResourcesMixin(customResources): { spec+: { features+: { orchestratorExplorer+: { customResources+: if std.isArray(v=customResources) then customResources else [customResources] } } } },
        '#withDdUrl':: d.fn(help='"Override the API endpoint for the Orchestrator Explorer.\\nURL Default: \\"https://orchestrator.datadoghq.com\\"."', args=[d.arg(name='ddUrl', type=d.T.string)]),
        withDdUrl(ddUrl): { spec+: { features+: { orchestratorExplorer+: { ddUrl: ddUrl } } } },
        '#withEnabled':: d.fn(help='"Enabled enables the Orchestrator Explorer.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { orchestratorExplorer+: { enabled: enabled } } } },
        '#withExtraTags':: d.fn(help='"Additional tags to associate with the collected data in the form of `a b c`.\\nThis is a Cluster Agent option distinct from DD_TAGS that is used in the Orchestrator Explorer."', args=[d.arg(name='extraTags', type=d.T.array)]),
        withExtraTags(extraTags): { spec+: { features+: { orchestratorExplorer+: { extraTags: if std.isArray(v=extraTags) then extraTags else [extraTags] } } } },
        '#withExtraTagsMixin':: d.fn(help='"Additional tags to associate with the collected data in the form of `a b c`.\\nThis is a Cluster Agent option distinct from DD_TAGS that is used in the Orchestrator Explorer."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='extraTags', type=d.T.array)]),
        withExtraTagsMixin(extraTags): { spec+: { features+: { orchestratorExplorer+: { extraTags+: if std.isArray(v=extraTags) then extraTags else [extraTags] } } } },
        '#withScrubContainers':: d.fn(help='"ScrubContainers enables scrubbing of sensitive container data (passwords, tokens, etc. ).\\nDefault: true"', args=[d.arg(name='scrubContainers', type=d.T.boolean)]),
        withScrubContainers(scrubContainers): { spec+: { features+: { orchestratorExplorer+: { scrubContainers: scrubContainers } } } },
      },
      '#otelCollector':: d.obj(help='"OtelCollector configuration."'),
      otelCollector: {
        '#conf':: d.obj(help='"Conf overrides the configuration for the default Kubernetes State Metrics Core check.\\nThis must point to a ConfigMap containing a valid cluster check configuration.\\nWhen passing a configmap, file name *must* be otel-config.yaml."'),
        conf: {
          '#configMap':: d.obj(help='"ConfigMap references an existing ConfigMap with the configuration file content."'),
          configMap: {
            '#items':: d.obj(help='"Items maps a ConfigMap data `key` to a file `path` mount."'),
            items: {
              '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help='"Items maps a ConfigMap data `key` to a file `path` mount."', args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { spec+: { features+: { otelCollector+: { conf+: { configMap+: { items: if std.isArray(v=items) then items else [items] } } } } } },
            '#withItemsMixin':: d.fn(help='"Items maps a ConfigMap data `key` to a file `path` mount."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { spec+: { features+: { otelCollector+: { conf+: { configMap+: { items+: if std.isArray(v=items) then items else [items] } } } } } },
            '#withName':: d.fn(help='"Name is the name of the ConfigMap."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { features+: { otelCollector+: { conf+: { configMap+: { name: name } } } } } },
          },
          '#withConfigData':: d.fn(help='"ConfigData corresponds to the configuration file content."', args=[d.arg(name='configData', type=d.T.string)]),
          withConfigData(configData): { spec+: { features+: { otelCollector+: { conf+: { configData: configData } } } } },
        },
        '#coreConfig':: d.obj(help='"OTelCollector Config Relevant to the Core agent"'),
        coreConfig: {
          '#withEnabled':: d.fn(help='"Enabled marks otelcollector as enabled in core agent."', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { otelCollector+: { coreConfig+: { enabled: enabled } } } } },
          '#withExtensionTimeout':: d.fn(help='"Extension URL provides the timout of the ddflareextension to\\nthe core agent."', args=[d.arg(name='extensionTimeout', type=d.T.integer)]),
          withExtensionTimeout(extensionTimeout): { spec+: { features+: { otelCollector+: { coreConfig+: { extensionTimeout: extensionTimeout } } } } },
          '#withExtensionURL':: d.fn(help='"Extension URL provides the URL of the ddflareextension to\\nthe core agent."', args=[d.arg(name='extensionURL', type=d.T.string)]),
          withExtensionURL(extensionURL): { spec+: { features+: { otelCollector+: { coreConfig+: { extensionURL: extensionURL } } } } },
        },
        '#ports':: d.obj(help='"Ports contains the ports for the otel-agent.\\nDefaults: otel-grpc:4317 / otel-http:4318. Note: setting 4317\\nor 4318 manually is *only* supported if name match default names (otel-grpc, otel-http).\\nIf not, this will lead to a port conflict.\\nThis limitation will be lifted once annotations support is removed."'),
        ports: {
          '#withContainerPort':: d.fn(help="\"Number of port to expose on the pod's IP address.\\nThis must be a valid port number, 0 \u003c x \u003c 65536.\"", args=[d.arg(name='containerPort', type=d.T.integer)]),
          withContainerPort(containerPort): { containerPort: containerPort },
          '#withHostIP':: d.fn(help='"What host IP to bind the external port to."', args=[d.arg(name='hostIP', type=d.T.string)]),
          withHostIP(hostIP): { hostIP: hostIP },
          '#withHostPort':: d.fn(help='"Number of port to expose on the host.\\nIf specified, this must be a valid port number, 0 < x < 65536.\\nIf HostNetwork is specified, this must match ContainerPort.\\nMost containers do not need this."', args=[d.arg(name='hostPort', type=d.T.integer)]),
          withHostPort(hostPort): { hostPort: hostPort },
          '#withName':: d.fn(help='"If specified, this must be an IANA_SVC_NAME and unique within the pod. Each\\nnamed port in a pod must have a unique name. Name for the port that can be\\nreferred to by services."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withProtocol':: d.fn(help='"Protocol for port. Must be UDP, TCP, or SCTP.\\nDefaults to \\"TCP\\"."', args=[d.arg(name='protocol', type=d.T.string)]),
          withProtocol(protocol): { protocol: protocol },
        },
        '#withEnabled':: d.fn(help='"Enabled enables the OTel Agent.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { otelCollector+: { enabled: enabled } } } },
        '#withPorts':: d.fn(help='"Ports contains the ports for the otel-agent.\\nDefaults: otel-grpc:4317 / otel-http:4318. Note: setting 4317\\nor 4318 manually is *only* supported if name match default names (otel-grpc, otel-http).\\nIf not, this will lead to a port conflict.\\nThis limitation will be lifted once annotations support is removed."', args=[d.arg(name='ports', type=d.T.array)]),
        withPorts(ports): { spec+: { features+: { otelCollector+: { ports: if std.isArray(v=ports) then ports else [ports] } } } },
        '#withPortsMixin':: d.fn(help='"Ports contains the ports for the otel-agent.\\nDefaults: otel-grpc:4317 / otel-http:4318. Note: setting 4317\\nor 4318 manually is *only* supported if name match default names (otel-grpc, otel-http).\\nIf not, this will lead to a port conflict.\\nThis limitation will be lifted once annotations support is removed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ports', type=d.T.array)]),
        withPortsMixin(ports): { spec+: { features+: { otelCollector+: { ports+: if std.isArray(v=ports) then ports else [ports] } } } },
      },
      '#otlp':: d.obj(help='"OTLP ingest configuration"'),
      otlp: {
        '#receiver':: d.obj(help='"Receiver contains configuration for the OTLP ingest receiver."'),
        receiver: {
          '#protocols':: d.obj(help='"Protocols contains configuration for the OTLP ingest receiver protocols."'),
          protocols: {
            '#grpc':: d.obj(help='"GRPC contains configuration for the OTLP ingest OTLP/gRPC receiver."'),
            grpc: {
              '#hostPortConfig':: d.obj(help='"Enable hostPort for OTLP/gRPC\\nDefault: true"'),
              hostPortConfig: {
                '#withEnabled':: d.fn(help='"Enabled enables host port configuration"', args=[d.arg(name='enabled', type=d.T.boolean)]),
                withEnabled(enabled): { spec+: { features+: { otlp+: { receiver+: { protocols+: { grpc+: { hostPortConfig+: { enabled: enabled } } } } } } } },
                '#withHostPort':: d.fn(help='"Port takes a port number (0 < x < 65536) to expose on the host. (Most containers do not need this.)\\nIf HostNetwork is enabled, this value must match the ContainerPort."', args=[d.arg(name='hostPort', type=d.T.integer)]),
                withHostPort(hostPort): { spec+: { features+: { otlp+: { receiver+: { protocols+: { grpc+: { hostPortConfig+: { hostPort: hostPort } } } } } } } },
              },
              '#withEnabled':: d.fn(help='"Enable the OTLP/gRPC endpoint. Host port is enabled by default and can be disabled."', args=[d.arg(name='enabled', type=d.T.boolean)]),
              withEnabled(enabled): { spec+: { features+: { otlp+: { receiver+: { protocols+: { grpc+: { enabled: enabled } } } } } } },
              '#withEndpoint':: d.fn(help="\"Endpoint for OTLP/gRPC.\\ngRPC supports several naming schemes: https://github.com/grpc/grpc/blob/master/doc/naming.md\\nThe Datadog Operator supports only 'host:port' (usually `0.0.0.0:port`).\\nDefault: `0.0.0.0:4317`.\"", args=[d.arg(name='endpoint', type=d.T.string)]),
              withEndpoint(endpoint): { spec+: { features+: { otlp+: { receiver+: { protocols+: { grpc+: { endpoint: endpoint } } } } } } },
            },
            '#http':: d.obj(help='"HTTP contains configuration for the OTLP ingest OTLP/HTTP receiver."'),
            http: {
              '#hostPortConfig':: d.obj(help='"Enable hostPorts for OTLP/HTTP\\nDefault: true"'),
              hostPortConfig: {
                '#withEnabled':: d.fn(help='"Enabled enables host port configuration"', args=[d.arg(name='enabled', type=d.T.boolean)]),
                withEnabled(enabled): { spec+: { features+: { otlp+: { receiver+: { protocols+: { http+: { hostPortConfig+: { enabled: enabled } } } } } } } },
                '#withHostPort':: d.fn(help='"Port takes a port number (0 < x < 65536) to expose on the host. (Most containers do not need this.)\\nIf HostNetwork is enabled, this value must match the ContainerPort."', args=[d.arg(name='hostPort', type=d.T.integer)]),
                withHostPort(hostPort): { spec+: { features+: { otlp+: { receiver+: { protocols+: { http+: { hostPortConfig+: { hostPort: hostPort } } } } } } } },
              },
              '#withEnabled':: d.fn(help='"Enable the OTLP/HTTP endpoint. Host port is enabled by default and can be disabled."', args=[d.arg(name='enabled', type=d.T.boolean)]),
              withEnabled(enabled): { spec+: { features+: { otlp+: { receiver+: { protocols+: { http+: { enabled: enabled } } } } } } },
              '#withEndpoint':: d.fn(help="\"Endpoint for OTLP/HTTP.\\nDefault: '0.0.0.0:4318'.\"", args=[d.arg(name='endpoint', type=d.T.string)]),
              withEndpoint(endpoint): { spec+: { features+: { otlp+: { receiver+: { protocols+: { http+: { endpoint: endpoint } } } } } } },
            },
          },
        },
      },
      '#processDiscovery':: d.obj(help='"ProcessDiscovery configuration."'),
      processDiscovery: {
        '#withEnabled':: d.fn(help='"Enabled enables the Process Discovery check in the Agent.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { processDiscovery+: { enabled: enabled } } } },
      },
      '#prometheusScrape':: d.obj(help='"PrometheusScrape configuration."'),
      prometheusScrape: {
        '#withAdditionalConfigs':: d.fn(help='"AdditionalConfigs allows adding advanced Prometheus check configurations with custom discovery rules."', args=[d.arg(name='additionalConfigs', type=d.T.string)]),
        withAdditionalConfigs(additionalConfigs): { spec+: { features+: { prometheusScrape+: { additionalConfigs: additionalConfigs } } } },
        '#withEnableServiceEndpoints':: d.fn(help='"EnableServiceEndpoints enables generating dedicated checks for service endpoints.\\nDefault: false"', args=[d.arg(name='enableServiceEndpoints', type=d.T.boolean)]),
        withEnableServiceEndpoints(enableServiceEndpoints): { spec+: { features+: { prometheusScrape+: { enableServiceEndpoints: enableServiceEndpoints } } } },
        '#withEnabled':: d.fn(help='"Enable autodiscovery of pods and services exposing Prometheus metrics.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { prometheusScrape+: { enabled: enabled } } } },
        '#withVersion':: d.fn(help='"Version specifies the version of the OpenMetrics check.\\nDefault: 2"', args=[d.arg(name='version', type=d.T.integer)]),
        withVersion(version): { spec+: { features+: { prometheusScrape+: { version: version } } } },
      },
      '#remoteConfiguration':: d.obj(help='"Remote Configuration configuration."'),
      remoteConfiguration: {
        '#withEnabled':: d.fn(help='"Enable this option to activate Remote Configuration.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { remoteConfiguration+: { enabled: enabled } } } },
      },
      '#sbom':: d.obj(help='"SBOM collection configuration."'),
      sbom: {
        '#containerImage':: d.obj(help='"SBOMTypeConfig contains configuration for a SBOM collection type."'),
        containerImage: {
          '#withAnalyzers':: d.fn(help='"Analyzers to use for SBOM collection."', args=[d.arg(name='analyzers', type=d.T.array)]),
          withAnalyzers(analyzers): { spec+: { features+: { sbom+: { containerImage+: { analyzers: if std.isArray(v=analyzers) then analyzers else [analyzers] } } } } },
          '#withAnalyzersMixin':: d.fn(help='"Analyzers to use for SBOM collection."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='analyzers', type=d.T.array)]),
          withAnalyzersMixin(analyzers): { spec+: { features+: { sbom+: { containerImage+: { analyzers+: if std.isArray(v=analyzers) then analyzers else [analyzers] } } } } },
          '#withEnabled':: d.fn(help='"Enable this option to activate SBOM collection.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { sbom+: { containerImage+: { enabled: enabled } } } } },
          '#withOverlayFSDirectScan':: d.fn(help='"Enable this option to enable experimental overlayFS direct scan.\\nDefault: false"', args=[d.arg(name='overlayFSDirectScan', type=d.T.boolean)]),
          withOverlayFSDirectScan(overlayFSDirectScan): { spec+: { features+: { sbom+: { containerImage+: { overlayFSDirectScan: overlayFSDirectScan } } } } },
          '#withUncompressedLayersSupport':: d.fn(help='"Enable this option to enable support for uncompressed layers.\\nDefault: false"', args=[d.arg(name='uncompressedLayersSupport', type=d.T.boolean)]),
          withUncompressedLayersSupport(uncompressedLayersSupport): { spec+: { features+: { sbom+: { containerImage+: { uncompressedLayersSupport: uncompressedLayersSupport } } } } },
        },
        '#host':: d.obj(help='"SBOMTypeConfig contains configuration for a SBOM collection type."'),
        host: {
          '#withAnalyzers':: d.fn(help='"Analyzers to use for SBOM collection."', args=[d.arg(name='analyzers', type=d.T.array)]),
          withAnalyzers(analyzers): { spec+: { features+: { sbom+: { host+: { analyzers: if std.isArray(v=analyzers) then analyzers else [analyzers] } } } } },
          '#withAnalyzersMixin':: d.fn(help='"Analyzers to use for SBOM collection."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='analyzers', type=d.T.array)]),
          withAnalyzersMixin(analyzers): { spec+: { features+: { sbom+: { host+: { analyzers+: if std.isArray(v=analyzers) then analyzers else [analyzers] } } } } },
          '#withEnabled':: d.fn(help='"Enable this option to activate SBOM collection.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { sbom+: { host+: { enabled: enabled } } } } },
        },
        '#withEnabled':: d.fn(help='"Enable this option to activate SBOM collection.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { sbom+: { enabled: enabled } } } },
      },
      '#serviceDiscovery':: d.obj(help='"ServiceDiscovery"'),
      serviceDiscovery: {
        '#networkStats':: d.obj(help='"Enables the service discovery network stats collection.\\nDefault: true"'),
        networkStats: {
          '#withEnabled':: d.fn(help='"Enables the Service Discovery Network Stats feature.\\nDefault: true"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { features+: { serviceDiscovery+: { networkStats+: { enabled: enabled } } } } },
        },
        '#withEnabled':: d.fn(help='"Enables the service discovery check.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { serviceDiscovery+: { enabled: enabled } } } },
      },
      '#tcpQueueLength':: d.obj(help='"TCPQueueLength configuration."'),
      tcpQueueLength: {
        '#withEnabled':: d.fn(help='"Enables the TCP queue length eBPF-based check.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { tcpQueueLength+: { enabled: enabled } } } },
      },
      '#usm':: d.obj(help='"USM (Universal Service Monitoring) configuration."'),
      usm: {
        '#withEnabled':: d.fn(help='"Enabled enables Universal Service Monitoring.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { features+: { usm+: { enabled: enabled } } } },
      },
    },
    '#global':: d.obj(help='"Global settings to configure the agents"'),
    global: {
      '#clusterAgentTokenSecret':: d.obj(help='"ClusterAgentTokenSecret is the secret containing the Cluster Agent token."'),
      clusterAgentTokenSecret: {
        '#withKeyName':: d.fn(help='"KeyName is the key of the secret to use."', args=[d.arg(name='keyName', type=d.T.string)]),
        withKeyName(keyName): { spec+: { global+: { clusterAgentTokenSecret+: { keyName: keyName } } } },
        '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
        withSecretName(secretName): { spec+: { global+: { clusterAgentTokenSecret+: { secretName: secretName } } } },
      },
      '#credentials':: d.obj(help='"Credentials defines the Datadog credentials used to submit data to/query data from Datadog."'),
      credentials: {
        '#apiSecret':: d.obj(help='"APISecret references an existing Secret which stores the API key instead of creating a new one.\\nIf set, this parameter takes precedence over \\"APIKey\\"."'),
        apiSecret: {
          '#withKeyName':: d.fn(help='"KeyName is the key of the secret to use."', args=[d.arg(name='keyName', type=d.T.string)]),
          withKeyName(keyName): { spec+: { global+: { credentials+: { apiSecret+: { keyName: keyName } } } } },
          '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
          withSecretName(secretName): { spec+: { global+: { credentials+: { apiSecret+: { secretName: secretName } } } } },
        },
        '#appSecret':: d.obj(help='"AppSecret references an existing Secret which stores the application key instead of creating a new one.\\nIf set, this parameter takes precedence over \\"AppKey\\"."'),
        appSecret: {
          '#withKeyName':: d.fn(help='"KeyName is the key of the secret to use."', args=[d.arg(name='keyName', type=d.T.string)]),
          withKeyName(keyName): { spec+: { global+: { credentials+: { appSecret+: { keyName: keyName } } } } },
          '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
          withSecretName(secretName): { spec+: { global+: { credentials+: { appSecret+: { secretName: secretName } } } } },
        },
        '#withApiKey':: d.fn(help='"APIKey configures your Datadog API key.\\nSee also: https://app.datadoghq.com/account/settings#agent/kubernetes"', args=[d.arg(name='apiKey', type=d.T.string)]),
        withApiKey(apiKey): { spec+: { global+: { credentials+: { apiKey: apiKey } } } },
        '#withAppKey':: d.fn(help='"AppKey configures your Datadog application key.\\nIf you are using features.externalMetricsServer.enabled = true, you must set\\na Datadog application key for read access to your metrics."', args=[d.arg(name='appKey', type=d.T.string)]),
        withAppKey(appKey): { spec+: { global+: { credentials+: { appKey: appKey } } } },
      },
      '#csi':: d.obj(help='"CSI contains configuration for Datadog CSI Driver"'),
      csi: {
        '#withEnabled':: d.fn(help='"Enables the usage of CSI driver in Datadog Agent.\\nRequires installation of Datadog CSI Driver https://github.com/DataDog/helm-charts/tree/main/charts/datadog-csi-driver\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { global+: { csi+: { enabled: enabled } } } },
      },
      '#endpoint':: d.obj(help='"Endpoint is the Datadog intake URL the Agent data are sent to.\\nOnly set this option if you need the Agent to send data to a custom URL.\\nOverrides the site setting defined in `Site`."'),
      endpoint: {
        '#credentials':: d.obj(help='"Credentials defines the Datadog credentials used to submit data to/query data from Datadog."'),
        credentials: {
          '#apiSecret':: d.obj(help='"APISecret references an existing Secret which stores the API key instead of creating a new one.\\nIf set, this parameter takes precedence over \\"APIKey\\"."'),
          apiSecret: {
            '#withKeyName':: d.fn(help='"KeyName is the key of the secret to use."', args=[d.arg(name='keyName', type=d.T.string)]),
            withKeyName(keyName): { spec+: { global+: { endpoint+: { credentials+: { apiSecret+: { keyName: keyName } } } } } },
            '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
            withSecretName(secretName): { spec+: { global+: { endpoint+: { credentials+: { apiSecret+: { secretName: secretName } } } } } },
          },
          '#appSecret':: d.obj(help='"AppSecret references an existing Secret which stores the application key instead of creating a new one.\\nIf set, this parameter takes precedence over \\"AppKey\\"."'),
          appSecret: {
            '#withKeyName':: d.fn(help='"KeyName is the key of the secret to use."', args=[d.arg(name='keyName', type=d.T.string)]),
            withKeyName(keyName): { spec+: { global+: { endpoint+: { credentials+: { appSecret+: { keyName: keyName } } } } } },
            '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
            withSecretName(secretName): { spec+: { global+: { endpoint+: { credentials+: { appSecret+: { secretName: secretName } } } } } },
          },
          '#withApiKey':: d.fn(help='"APIKey configures your Datadog API key.\\nSee also: https://app.datadoghq.com/account/settings#agent/kubernetes"', args=[d.arg(name='apiKey', type=d.T.string)]),
          withApiKey(apiKey): { spec+: { global+: { endpoint+: { credentials+: { apiKey: apiKey } } } } },
          '#withAppKey':: d.fn(help='"AppKey configures your Datadog application key.\\nIf you are using features.externalMetricsServer.enabled = true, you must set\\na Datadog application key for read access to your metrics."', args=[d.arg(name='appKey', type=d.T.string)]),
          withAppKey(appKey): { spec+: { global+: { endpoint+: { credentials+: { appKey: appKey } } } } },
        },
        '#withUrl':: d.fn(help='"URL defines the endpoint URL."', args=[d.arg(name='url', type=d.T.string)]),
        withUrl(url): { spec+: { global+: { endpoint+: { url: url } } } },
      },
      '#env':: d.obj(help='"Env contains a list of environment variables that are set for all Agents."'),
      env: {
        '#valueFrom':: d.obj(help="\"Source for the environment variable's value. Cannot be used if value is not empty.\""),
        valueFrom: {
          '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
          configMapKeyRef: {
            '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { valueFrom+: { configMapKeyRef+: { key: key } } },
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { valueFrom+: { configMapKeyRef+: { name: name } } },
            '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { valueFrom+: { configMapKeyRef+: { optional: optional } } },
          },
          '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
          fieldRef: {
            '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
            withApiVersion(apiVersion): { valueFrom+: { fieldRef+: { apiVersion: apiVersion } } },
            '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
            withFieldPath(fieldPath): { valueFrom+: { fieldRef+: { fieldPath: fieldPath } } },
          },
          '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
          resourceFieldRef: {
            '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
            withContainerName(containerName): { valueFrom+: { resourceFieldRef+: { containerName: containerName } } },
            '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
            withDivisor(divisor): { valueFrom+: { resourceFieldRef+: { divisor: divisor } } },
            '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
            withResource(resource): { valueFrom+: { resourceFieldRef+: { resource: resource } } },
          },
          '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
          secretKeyRef: {
            '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { valueFrom+: { secretKeyRef+: { key: key } } },
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { valueFrom+: { secretKeyRef+: { name: name } } },
            '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { valueFrom+: { secretKeyRef+: { optional: optional } } },
          },
        },
        '#withName':: d.fn(help='"Name of the environment variable. Must be a C_IDENTIFIER."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
        withValue(value): { value: value },
      },
      '#fips':: d.obj(help='"FIPS contains configuration used to customize the FIPS proxy sidecar."'),
      fips: {
        '#customFIPSConfig':: d.obj(help='"CustomFIPSConfig configures a custom configMap to provide the FIPS configuration.\\nSpecify custom contents for the FIPS proxy sidecar container config\\n(/etc/datadog-fips-proxy/datadog-fips-proxy.cfg). If empty, the default FIPS\\nproxy sidecar container config is used."'),
        customFIPSConfig: {
          '#configMap':: d.obj(help='"ConfigMap references an existing ConfigMap with the configuration file content."'),
          configMap: {
            '#items':: d.obj(help='"Items maps a ConfigMap data `key` to a file `path` mount."'),
            items: {
              '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help='"Items maps a ConfigMap data `key` to a file `path` mount."', args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { spec+: { global+: { fips+: { customFIPSConfig+: { configMap+: { items: if std.isArray(v=items) then items else [items] } } } } } },
            '#withItemsMixin':: d.fn(help='"Items maps a ConfigMap data `key` to a file `path` mount."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { spec+: { global+: { fips+: { customFIPSConfig+: { configMap+: { items+: if std.isArray(v=items) then items else [items] } } } } } },
            '#withName':: d.fn(help='"Name is the name of the ConfigMap."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { global+: { fips+: { customFIPSConfig+: { configMap+: { name: name } } } } } },
          },
          '#withConfigData':: d.fn(help='"ConfigData corresponds to the configuration file content."', args=[d.arg(name='configData', type=d.T.string)]),
          withConfigData(configData): { spec+: { global+: { fips+: { customFIPSConfig+: { configData: configData } } } } },
        },
        '#image':: d.obj(help='"The container image of the FIPS sidecar."'),
        image: {
          '#pullSecrets':: d.obj(help='"It is possible to specify Docker registry credentials.\\nSee https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod"'),
          pullSecrets: {
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
          },
          '#withJmxEnabled':: d.fn(help='"Define whether the Agent image should support JMX.\\nTo be used if the `Name` field does not correspond to a full image string."', args=[d.arg(name='jmxEnabled', type=d.T.boolean)]),
          withJmxEnabled(jmxEnabled): { spec+: { global+: { fips+: { image+: { jmxEnabled: jmxEnabled } } } } },
          '#withName':: d.fn(help='"Defines the Agent image name for the pod. You can provide this as:\\n* `<NAME>` - Use `agent` for the Datadog Agent, `cluster-agent` for the Datadog Cluster Agent, or `dogstatsd`\\nfor DogStatsD. The full image string is derived from `global.registry`, `[key].image.tag`, and `[key].image.jmxEnabled`.\\n* `<NAME>:<TAG>` - For example, `agent:latest`. The registry is derived from `global.registry`. `[key].image.tag`\\nand `[key].image.jmxEnabled` are ignored.\\n* `<REGISTRY>/<NAME>:<TAG>` - For example, `gcr.io/datadoghq/agent:latest`. If the full image string is specified\\n  like this, then `global.registry`, `[key].image.tag`, and `[key].image.jmxEnabled` are ignored."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { global+: { fips+: { image+: { name: name } } } } },
          '#withPullPolicy':: d.fn(help='"The Kubernetes pull policy:\\nUse `Always`, `Never`, or `IfNotPresent`."', args=[d.arg(name='pullPolicy', type=d.T.string)]),
          withPullPolicy(pullPolicy): { spec+: { global+: { fips+: { image+: { pullPolicy: pullPolicy } } } } },
          '#withPullSecrets':: d.fn(help='"It is possible to specify Docker registry credentials.\\nSee https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod"', args=[d.arg(name='pullSecrets', type=d.T.array)]),
          withPullSecrets(pullSecrets): { spec+: { global+: { fips+: { image+: { pullSecrets: if std.isArray(v=pullSecrets) then pullSecrets else [pullSecrets] } } } } },
          '#withPullSecretsMixin':: d.fn(help='"It is possible to specify Docker registry credentials.\\nSee https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='pullSecrets', type=d.T.array)]),
          withPullSecretsMixin(pullSecrets): { spec+: { global+: { fips+: { image+: { pullSecrets+: if std.isArray(v=pullSecrets) then pullSecrets else [pullSecrets] } } } } },
          '#withTag':: d.fn(help='"Define the image tag to use.\\nTo be used if the `Name` field does not correspond to a full image string."', args=[d.arg(name='tag', type=d.T.string)]),
          withTag(tag): { spec+: { global+: { fips+: { image+: { tag: tag } } } } },
        },
        '#resources':: d.obj(help='"Resources is the requests and limits for the FIPS sidecar container."'),
        resources: {
          '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
          claims: {
            '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
            withRequest(request): { request: request },
          },
          '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
          withClaims(claims): { spec+: { global+: { fips+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } },
          '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
          withClaimsMixin(claims): { spec+: { global+: { fips+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } },
          '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
          withLimits(limits): { spec+: { global+: { fips+: { resources+: { limits: limits } } } } },
          '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
          withLimitsMixin(limits): { spec+: { global+: { fips+: { resources+: { limits+: limits } } } } },
          '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
          withRequests(requests): { spec+: { global+: { fips+: { resources+: { requests: requests } } } } },
          '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
          withRequestsMixin(requests): { spec+: { global+: { fips+: { resources+: { requests+: requests } } } } },
        },
        '#withEnabled':: d.fn(help='"Enable FIPS sidecar."', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { global+: { fips+: { enabled: enabled } } } },
        '#withLocalAddress':: d.fn(help='"Set the local IP address.\\nDefault: `127.0.0.1`"', args=[d.arg(name='localAddress', type=d.T.string)]),
        withLocalAddress(localAddress): { spec+: { global+: { fips+: { localAddress: localAddress } } } },
        '#withPort':: d.fn(help='"Port specifies which port is used by the containers to communicate to the FIPS sidecar.\\nDefault: 9803"', args=[d.arg(name='port', type=d.T.integer)]),
        withPort(port): { spec+: { global+: { fips+: { port: port } } } },
        '#withPortRange':: d.fn(help='"PortRange specifies the number of ports used.\\nDefault: 15"', args=[d.arg(name='portRange', type=d.T.integer)]),
        withPortRange(portRange): { spec+: { global+: { fips+: { portRange: portRange } } } },
        '#withUseHTTPS':: d.fn(help='"UseHTTPS enables HTTPS.\\nDefault: false"', args=[d.arg(name='useHTTPS', type=d.T.boolean)]),
        withUseHTTPS(useHTTPS): { spec+: { global+: { fips+: { useHTTPS: useHTTPS } } } },
      },
      '#kubelet':: d.obj(help='"Kubelet contains the kubelet configuration parameters."'),
      kubelet: {
        '#host':: d.obj(help='"Host overrides the host used to contact kubelet API (default to status.hostIP)."'),
        host: {
          '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
          configMapKeyRef: {
            '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { spec+: { global+: { kubelet+: { host+: { configMapKeyRef+: { key: key } } } } } },
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { global+: { kubelet+: { host+: { configMapKeyRef+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { global+: { kubelet+: { host+: { configMapKeyRef+: { optional: optional } } } } } },
          },
          '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
          fieldRef: {
            '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
            withApiVersion(apiVersion): { spec+: { global+: { kubelet+: { host+: { fieldRef+: { apiVersion: apiVersion } } } } } },
            '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
            withFieldPath(fieldPath): { spec+: { global+: { kubelet+: { host+: { fieldRef+: { fieldPath: fieldPath } } } } } },
          },
          '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
          resourceFieldRef: {
            '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
            withContainerName(containerName): { spec+: { global+: { kubelet+: { host+: { resourceFieldRef+: { containerName: containerName } } } } } },
            '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
            withDivisor(divisor): { spec+: { global+: { kubelet+: { host+: { resourceFieldRef+: { divisor: divisor } } } } } },
            '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
            withResource(resource): { spec+: { global+: { kubelet+: { host+: { resourceFieldRef+: { resource: resource } } } } } },
          },
          '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
          secretKeyRef: {
            '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { spec+: { global+: { kubelet+: { host+: { secretKeyRef+: { key: key } } } } } },
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { global+: { kubelet+: { host+: { secretKeyRef+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { global+: { kubelet+: { host+: { secretKeyRef+: { optional: optional } } } } } },
          },
        },
        '#withAgentCAPath':: d.fn(help="\"AgentCAPath is the container path where the kubelet CA certificate is stored.\\nDefault: '/var/run/host-kubelet-ca.crt' if hostCAPath is set, else '/var/run/secrets/kubernetes.io/serviceaccount/ca.crt'\"", args=[d.arg(name='agentCAPath', type=d.T.string)]),
        withAgentCAPath(agentCAPath): { spec+: { global+: { kubelet+: { agentCAPath: agentCAPath } } } },
        '#withHostCAPath':: d.fn(help='"HostCAPath is the host path where the kubelet CA certificate is stored."', args=[d.arg(name='hostCAPath', type=d.T.string)]),
        withHostCAPath(hostCAPath): { spec+: { global+: { kubelet+: { hostCAPath: hostCAPath } } } },
        '#withPodResourcesSocketPath':: d.fn(help='"PodResourcesSocketPath is the host path where the pod resources socket is stored.\\nDefault: `/var/lib/kubelet/pod-resources/`"', args=[d.arg(name='podResourcesSocketPath', type=d.T.string)]),
        withPodResourcesSocketPath(podResourcesSocketPath): { spec+: { global+: { kubelet+: { podResourcesSocketPath: podResourcesSocketPath } } } },
        '#withTlsVerify':: d.fn(help='"TLSVerify toggles kubelet TLS verification.\\nDefault: true"', args=[d.arg(name='tlsVerify', type=d.T.boolean)]),
        withTlsVerify(tlsVerify): { spec+: { global+: { kubelet+: { tlsVerify: tlsVerify } } } },
      },
      '#localService':: d.obj(help='"LocalService contains configuration to customize the internal traffic policy service."'),
      localService: {
        '#withForceEnableLocalService':: d.fn(help='"ForceEnableLocalService forces the creation of the internal traffic policy service to target the agent running on the local node.\\nThis parameter only applies to Kubernetes 1.21, where the feature is in alpha and is disabled by default.\\n(On Kubernetes 1.22+, the feature entered beta and the internal traffic service is created by default, so this parameter is ignored.)\\nDefault: false"', args=[d.arg(name='forceEnableLocalService', type=d.T.boolean)]),
        withForceEnableLocalService(forceEnableLocalService): { spec+: { global+: { localService+: { forceEnableLocalService: forceEnableLocalService } } } },
        '#withNameOverride':: d.fn(help='"NameOverride defines the name of the internal traffic service to target the agent running on the local node."', args=[d.arg(name='nameOverride', type=d.T.string)]),
        withNameOverride(nameOverride): { spec+: { global+: { localService+: { nameOverride: nameOverride } } } },
      },
      '#networkPolicy':: d.obj(help='"NetworkPolicy contains the network configuration."'),
      networkPolicy: {
        '#dnsSelectorEndpoints':: d.obj(help='"DNSSelectorEndpoints defines the cilium selector of the DNS\\u202fserver entity."'),
        dnsSelectorEndpoints: {
          '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
          matchExpressions: {
            '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
            withOperator(operator): { operator: operator },
            '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
            withValues(values): { values: if std.isArray(v=values) then values else [values] },
            '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
            withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
          },
          '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
          withMatchExpressions(matchExpressions): { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
          '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
          withMatchExpressionsMixin(matchExpressions): { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
          '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { matchLabels: matchLabels },
          '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { matchLabels+: matchLabels },
        },
        '#withCreate':: d.fn(help='"Create defines whether to create a NetworkPolicy for the current deployment."', args=[d.arg(name='create', type=d.T.boolean)]),
        withCreate(create): { spec+: { global+: { networkPolicy+: { create: create } } } },
        '#withDnsSelectorEndpoints':: d.fn(help='"DNSSelectorEndpoints defines the cilium selector of the DNS\\u202fserver entity."', args=[d.arg(name='dnsSelectorEndpoints', type=d.T.array)]),
        withDnsSelectorEndpoints(dnsSelectorEndpoints): { spec+: { global+: { networkPolicy+: { dnsSelectorEndpoints: if std.isArray(v=dnsSelectorEndpoints) then dnsSelectorEndpoints else [dnsSelectorEndpoints] } } } },
        '#withDnsSelectorEndpointsMixin':: d.fn(help='"DNSSelectorEndpoints defines the cilium selector of the DNS\\u202fserver entity."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='dnsSelectorEndpoints', type=d.T.array)]),
        withDnsSelectorEndpointsMixin(dnsSelectorEndpoints): { spec+: { global+: { networkPolicy+: { dnsSelectorEndpoints+: if std.isArray(v=dnsSelectorEndpoints) then dnsSelectorEndpoints else [dnsSelectorEndpoints] } } } },
        '#withFlavor':: d.fn(help='"Flavor defines Which network policy to use."', args=[d.arg(name='flavor', type=d.T.string)]),
        withFlavor(flavor): { spec+: { global+: { networkPolicy+: { flavor: flavor } } } },
      },
      '#originDetectionUnified':: d.obj(help='"OriginDetectionUnified defines the origin detection unified mechanism behavior."'),
      originDetectionUnified: {
        '#withEnabled':: d.fn(help='"Enabled enables unified mechanism for origin detection.\\nDefault: false"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { global+: { originDetectionUnified+: { enabled: enabled } } } },
      },
      '#secretBackend':: d.obj(help='"Configure the secret backend feature https://docs.datadoghq.com/agent/guide/secrets-management\\nSee also: https://github.com/DataDog/datadog-operator/blob/main/docs/secret_management.md"'),
      secretBackend: {
        '#roles':: d.obj(help='"Roles for Datadog to read the specified secrets, replacing `enableGlobalPermissions`.\\nThey are defined as a list of namespace/secrets.\\nEach defined namespace needs to be present in the DatadogAgent controller using `WATCH_NAMESPACE` or `DD_AGENT_WATCH_NAMESPACE`.\\nSee also: https://github.com/DataDog/datadog-operator/blob/main/docs/secret_management.md#how-to-deploy-the-agent-components-using-the-secret-backend-feature-with-datadogagent."'),
        roles: {
          '#withNamespace':: d.fn(help='"Namespace defines the namespace in which the secrets reside."', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { namespace: namespace },
          '#withSecrets':: d.fn(help='"Secrets defines the list of secrets for which a role should be created."', args=[d.arg(name='secrets', type=d.T.array)]),
          withSecrets(secrets): { secrets: if std.isArray(v=secrets) then secrets else [secrets] },
          '#withSecretsMixin':: d.fn(help='"Secrets defines the list of secrets for which a role should be created."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='secrets', type=d.T.array)]),
          withSecretsMixin(secrets): { secrets+: if std.isArray(v=secrets) then secrets else [secrets] },
        },
        '#withArgs':: d.fn(help='"List of arguments to pass to the command (space-separated strings)."', args=[d.arg(name='args', type=d.T.string)]),
        withArgs(args): { spec+: { global+: { secretBackend+: { args: args } } } },
        '#withCommand':: d.fn(help='"The secret backend command to use. Datadog provides a pre-defined binary `/readsecret_multiple_providers.sh`.\\nRead more about `/readsecret_multiple_providers.sh` at https://docs.datadoghq.com/agent/configuration/secrets-management/?tab=linux#script-for-reading-from-multiple-secret-providers."', args=[d.arg(name='command', type=d.T.string)]),
        withCommand(command): { spec+: { global+: { secretBackend+: { command: command } } } },
        '#withEnableGlobalPermissions':: d.fn(help='"Whether to create a global permission allowing Datadog agents to read all Kubernetes secrets.\\nDefault: `false`."', args=[d.arg(name='enableGlobalPermissions', type=d.T.boolean)]),
        withEnableGlobalPermissions(enableGlobalPermissions): { spec+: { global+: { secretBackend+: { enableGlobalPermissions: enableGlobalPermissions } } } },
        '#withRefreshInterval':: d.fn(help='"The refresh interval for secrets (0 disables refreshing).\\nDefault: `0`."', args=[d.arg(name='refreshInterval', type=d.T.integer)]),
        withRefreshInterval(refreshInterval): { spec+: { global+: { secretBackend+: { refreshInterval: refreshInterval } } } },
        '#withRoles':: d.fn(help='"Roles for Datadog to read the specified secrets, replacing `enableGlobalPermissions`.\\nThey are defined as a list of namespace/secrets.\\nEach defined namespace needs to be present in the DatadogAgent controller using `WATCH_NAMESPACE` or `DD_AGENT_WATCH_NAMESPACE`.\\nSee also: https://github.com/DataDog/datadog-operator/blob/main/docs/secret_management.md#how-to-deploy-the-agent-components-using-the-secret-backend-feature-with-datadogagent."', args=[d.arg(name='roles', type=d.T.array)]),
        withRoles(roles): { spec+: { global+: { secretBackend+: { roles: if std.isArray(v=roles) then roles else [roles] } } } },
        '#withRolesMixin':: d.fn(help='"Roles for Datadog to read the specified secrets, replacing `enableGlobalPermissions`.\\nThey are defined as a list of namespace/secrets.\\nEach defined namespace needs to be present in the DatadogAgent controller using `WATCH_NAMESPACE` or `DD_AGENT_WATCH_NAMESPACE`.\\nSee also: https://github.com/DataDog/datadog-operator/blob/main/docs/secret_management.md#how-to-deploy-the-agent-components-using-the-secret-backend-feature-with-datadogagent."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='roles', type=d.T.array)]),
        withRolesMixin(roles): { spec+: { global+: { secretBackend+: { roles+: if std.isArray(v=roles) then roles else [roles] } } } },
        '#withTimeout':: d.fn(help='"The command timeout in seconds.\\nDefault: `30`."', args=[d.arg(name='timeout', type=d.T.integer)]),
        withTimeout(timeout): { spec+: { global+: { secretBackend+: { timeout: timeout } } } },
      },
      '#withChecksTagCardinality':: d.fn(help='"ChecksTagCardinality configures tag cardinality for the metrics collected by integrations (`low`, `orchestrator` or `high`).\\nSee also: https://docs.datadoghq.com/getting_started/tagging/assigning_tags/?tab=containerizedenvironments#tags-cardinality.\\nNot set by default to avoid overriding existing DD_CHECKS_TAG_CARDINALITY configurations, the default value in the Agent is low.\\nRef: https://github.com/DataDog/datadog-agent/blob/856cf4a66142ce91fd4f8a278149436eb971184a/pkg/config/setup/config.go#L625."', args=[d.arg(name='checksTagCardinality', type=d.T.string)]),
      withChecksTagCardinality(checksTagCardinality): { spec+: { global+: { checksTagCardinality: checksTagCardinality } } },
      '#withClusterAgentToken':: d.fn(help='"ClusterAgentToken is the token for communication between the NodeAgent and ClusterAgent."', args=[d.arg(name='clusterAgentToken', type=d.T.string)]),
      withClusterAgentToken(clusterAgentToken): { spec+: { global+: { clusterAgentToken: clusterAgentToken } } },
      '#withClusterName':: d.fn(help='"ClusterName sets a unique cluster name for the deployment to easily scope monitoring data in the Datadog app."', args=[d.arg(name='clusterName', type=d.T.string)]),
      withClusterName(clusterName): { spec+: { global+: { clusterName: clusterName } } },
      '#withContainerStrategy':: d.fn(help="\"ContainerStrategy determines whether agents run in a single or multiple containers.\\nDefault: 'optimized'\"", args=[d.arg(name='containerStrategy', type=d.T.string)]),
      withContainerStrategy(containerStrategy): { spec+: { global+: { containerStrategy: containerStrategy } } },
      '#withCriSocketPath':: d.fn(help='"Path to the container runtime socket (if different from Docker)."', args=[d.arg(name='criSocketPath', type=d.T.string)]),
      withCriSocketPath(criSocketPath): { spec+: { global+: { criSocketPath: criSocketPath } } },
      '#withDisableNonResourceRules':: d.fn(help="\"Set DisableNonResourceRules to exclude NonResourceURLs from default ClusterRoles.\\nRequired 'true' for Google Cloud Marketplace.\"", args=[d.arg(name='disableNonResourceRules', type=d.T.boolean)]),
      withDisableNonResourceRules(disableNonResourceRules): { spec+: { global+: { disableNonResourceRules: disableNonResourceRules } } },
      '#withDockerSocketPath':: d.fn(help='"Path to the docker runtime socket."', args=[d.arg(name='dockerSocketPath', type=d.T.string)]),
      withDockerSocketPath(dockerSocketPath): { spec+: { global+: { dockerSocketPath: dockerSocketPath } } },
      '#withEnv':: d.fn(help='"Env contains a list of environment variables that are set for all Agents."', args=[d.arg(name='env', type=d.T.array)]),
      withEnv(env): { spec+: { global+: { env: if std.isArray(v=env) then env else [env] } } },
      '#withEnvMixin':: d.fn(help='"Env contains a list of environment variables that are set for all Agents."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
      withEnvMixin(env): { spec+: { global+: { env+: if std.isArray(v=env) then env else [env] } } },
      '#withKubernetesResourcesAnnotationsAsTags':: d.fn(help='"Provide a mapping of Kubernetes Resource Groups to annotations mapping to Datadog Tags.\\n<KUBERNETES_RESOURCE_GROUP>:\\n\\t\\t<KUBERNETES_ANNOTATION>: <DATADOG_TAG_KEY>\\nKUBERNETES_RESOURCE_GROUP should be in the form `{resource}.{group}` or `{resource}` (example: deployments.apps, pods)"', args=[d.arg(name='kubernetesResourcesAnnotationsAsTags', type=d.T.object)]),
      withKubernetesResourcesAnnotationsAsTags(kubernetesResourcesAnnotationsAsTags): { spec+: { global+: { kubernetesResourcesAnnotationsAsTags: kubernetesResourcesAnnotationsAsTags } } },
      '#withKubernetesResourcesAnnotationsAsTagsMixin':: d.fn(help='"Provide a mapping of Kubernetes Resource Groups to annotations mapping to Datadog Tags.\\n<KUBERNETES_RESOURCE_GROUP>:\\n\\t\\t<KUBERNETES_ANNOTATION>: <DATADOG_TAG_KEY>\\nKUBERNETES_RESOURCE_GROUP should be in the form `{resource}.{group}` or `{resource}` (example: deployments.apps, pods)"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='kubernetesResourcesAnnotationsAsTags', type=d.T.object)]),
      withKubernetesResourcesAnnotationsAsTagsMixin(kubernetesResourcesAnnotationsAsTags): { spec+: { global+: { kubernetesResourcesAnnotationsAsTags+: kubernetesResourcesAnnotationsAsTags } } },
      '#withKubernetesResourcesLabelsAsTags':: d.fn(help='"Provide a mapping of Kubernetes Resource Groups to labels mapping to Datadog Tags.\\n<KUBERNETES_RESOURCE_GROUP>:\\n\\t\\t<KUBERNETES_LABEL>: <DATADOG_TAG_KEY>\\nKUBERNETES_RESOURCE_GROUP should be in the form `{resource}.{group}` or `{resource}` (example: deployments.apps, pods)"', args=[d.arg(name='kubernetesResourcesLabelsAsTags', type=d.T.object)]),
      withKubernetesResourcesLabelsAsTags(kubernetesResourcesLabelsAsTags): { spec+: { global+: { kubernetesResourcesLabelsAsTags: kubernetesResourcesLabelsAsTags } } },
      '#withKubernetesResourcesLabelsAsTagsMixin':: d.fn(help='"Provide a mapping of Kubernetes Resource Groups to labels mapping to Datadog Tags.\\n<KUBERNETES_RESOURCE_GROUP>:\\n\\t\\t<KUBERNETES_LABEL>: <DATADOG_TAG_KEY>\\nKUBERNETES_RESOURCE_GROUP should be in the form `{resource}.{group}` or `{resource}` (example: deployments.apps, pods)"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='kubernetesResourcesLabelsAsTags', type=d.T.object)]),
      withKubernetesResourcesLabelsAsTagsMixin(kubernetesResourcesLabelsAsTags): { spec+: { global+: { kubernetesResourcesLabelsAsTags+: kubernetesResourcesLabelsAsTags } } },
      '#withLogLevel':: d.fn(help="\"LogLevel sets logging verbosity. This can be overridden by container.\\nValid log levels are: trace, debug, info, warn, error, critical, and off.\\nDefault: 'info'\"", args=[d.arg(name='logLevel', type=d.T.string)]),
      withLogLevel(logLevel): { spec+: { global+: { logLevel: logLevel } } },
      '#withNamespaceAnnotationsAsTags':: d.fn(help='"Provide a mapping of Kubernetes Namespace Annotations to Datadog Tags.\\n<KUBERNETES_LABEL>: <DATADOG_TAG_KEY>"', args=[d.arg(name='namespaceAnnotationsAsTags', type=d.T.object)]),
      withNamespaceAnnotationsAsTags(namespaceAnnotationsAsTags): { spec+: { global+: { namespaceAnnotationsAsTags: namespaceAnnotationsAsTags } } },
      '#withNamespaceAnnotationsAsTagsMixin':: d.fn(help='"Provide a mapping of Kubernetes Namespace Annotations to Datadog Tags.\\n<KUBERNETES_LABEL>: <DATADOG_TAG_KEY>"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='namespaceAnnotationsAsTags', type=d.T.object)]),
      withNamespaceAnnotationsAsTagsMixin(namespaceAnnotationsAsTags): { spec+: { global+: { namespaceAnnotationsAsTags+: namespaceAnnotationsAsTags } } },
      '#withNamespaceLabelsAsTags':: d.fn(help='"Provide a mapping of Kubernetes Namespace Labels to Datadog Tags.\\n<KUBERNETES_NAMESPACE_LABEL>: <DATADOG_TAG_KEY>"', args=[d.arg(name='namespaceLabelsAsTags', type=d.T.object)]),
      withNamespaceLabelsAsTags(namespaceLabelsAsTags): { spec+: { global+: { namespaceLabelsAsTags: namespaceLabelsAsTags } } },
      '#withNamespaceLabelsAsTagsMixin':: d.fn(help='"Provide a mapping of Kubernetes Namespace Labels to Datadog Tags.\\n<KUBERNETES_NAMESPACE_LABEL>: <DATADOG_TAG_KEY>"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='namespaceLabelsAsTags', type=d.T.object)]),
      withNamespaceLabelsAsTagsMixin(namespaceLabelsAsTags): { spec+: { global+: { namespaceLabelsAsTags+: namespaceLabelsAsTags } } },
      '#withNodeLabelsAsTags':: d.fn(help='"Provide a mapping of Kubernetes Node Labels to Datadog Tags.\\n<KUBERNETES_NODE_LABEL>: <DATADOG_TAG_KEY>"', args=[d.arg(name='nodeLabelsAsTags', type=d.T.object)]),
      withNodeLabelsAsTags(nodeLabelsAsTags): { spec+: { global+: { nodeLabelsAsTags: nodeLabelsAsTags } } },
      '#withNodeLabelsAsTagsMixin':: d.fn(help='"Provide a mapping of Kubernetes Node Labels to Datadog Tags.\\n<KUBERNETES_NODE_LABEL>: <DATADOG_TAG_KEY>"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeLabelsAsTags', type=d.T.object)]),
      withNodeLabelsAsTagsMixin(nodeLabelsAsTags): { spec+: { global+: { nodeLabelsAsTags+: nodeLabelsAsTags } } },
      '#withPodAnnotationsAsTags':: d.fn(help='"Provide a mapping of Kubernetes Annotations to Datadog Tags.\\n<KUBERNETES_ANNOTATIONS>: <DATADOG_TAG_KEY>"', args=[d.arg(name='podAnnotationsAsTags', type=d.T.object)]),
      withPodAnnotationsAsTags(podAnnotationsAsTags): { spec+: { global+: { podAnnotationsAsTags: podAnnotationsAsTags } } },
      '#withPodAnnotationsAsTagsMixin':: d.fn(help='"Provide a mapping of Kubernetes Annotations to Datadog Tags.\\n<KUBERNETES_ANNOTATIONS>: <DATADOG_TAG_KEY>"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='podAnnotationsAsTags', type=d.T.object)]),
      withPodAnnotationsAsTagsMixin(podAnnotationsAsTags): { spec+: { global+: { podAnnotationsAsTags+: podAnnotationsAsTags } } },
      '#withPodLabelsAsTags':: d.fn(help='"Provide a mapping of Kubernetes Labels to Datadog Tags.\\n<KUBERNETES_LABEL>: <DATADOG_TAG_KEY>"', args=[d.arg(name='podLabelsAsTags', type=d.T.object)]),
      withPodLabelsAsTags(podLabelsAsTags): { spec+: { global+: { podLabelsAsTags: podLabelsAsTags } } },
      '#withPodLabelsAsTagsMixin':: d.fn(help='"Provide a mapping of Kubernetes Labels to Datadog Tags.\\n<KUBERNETES_LABEL>: <DATADOG_TAG_KEY>"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='podLabelsAsTags', type=d.T.object)]),
      withPodLabelsAsTagsMixin(podLabelsAsTags): { spec+: { global+: { podLabelsAsTags+: podLabelsAsTags } } },
      '#withRegistry':: d.fn(help="\"Registry is the image registry to use for all Agent images.\\nUse 'public.ecr.aws/datadog' for AWS ECR.\\nUse 'datadoghq.azurecr.io' for Azure Container Registry.\\nUse 'gcr.io/datadoghq' for Google Container Registry.\\nUse 'eu.gcr.io/datadoghq' for Google Container Registry in the EU region.\\nUse 'asia.gcr.io/datadoghq' for Google Container Registry in the Asia region.\\nUse 'docker.io/datadog' for DockerHub.\\nDefault: 'gcr.io/datadoghq'\"", args=[d.arg(name='registry', type=d.T.string)]),
      withRegistry(registry): { spec+: { global+: { registry: registry } } },
      '#withSite':: d.fn(help="\"Site is the Datadog intake site Agent data are sent to.\\nSet to 'datadoghq.com' to send data to the US1 site (default).\\nSet to 'datadoghq.eu' to send data to the EU site.\\nSet to 'us3.datadoghq.com' to send data to the US3 site.\\nSet to 'us5.datadoghq.com' to send data to the US5 site.\\nSet to 'ddog-gov.com' to send data to the US1-FED site.\\nSet to 'ap1.datadoghq.com' to send data to the AP1 site.\\nDefault: 'datadoghq.com'\"", args=[d.arg(name='site', type=d.T.string)]),
      withSite(site): { spec+: { global+: { site: site } } },
      '#withTags':: d.fn(help='"Tags contains a list of tags to attach to every metric, event and service check collected.\\nLearn more about tagging: https://docs.datadoghq.com/tagging/"', args=[d.arg(name='tags', type=d.T.array)]),
      withTags(tags): { spec+: { global+: { tags: if std.isArray(v=tags) then tags else [tags] } } },
      '#withTagsMixin':: d.fn(help='"Tags contains a list of tags to attach to every metric, event and service check collected.\\nLearn more about tagging: https://docs.datadoghq.com/tagging/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tags', type=d.T.array)]),
      withTagsMixin(tags): { spec+: { global+: { tags+: if std.isArray(v=tags) then tags else [tags] } } },
      '#withUseFIPSAgent':: d.fn(help="\"UseFIPSAgent enables the FIPS flavor of the Agent. If 'true', the FIPS proxy will always be disabled.\\nDefault: 'false'\"", args=[d.arg(name='useFIPSAgent', type=d.T.boolean)]),
      withUseFIPSAgent(useFIPSAgent): { spec+: { global+: { useFIPSAgent: useFIPSAgent } } },
    },
    '#withOverride':: d.fn(help='"Override the default configurations of the agents"', args=[d.arg(name='override', type=d.T.object)]),
    withOverride(override): { spec+: { override: override } },
    '#withOverrideMixin':: d.fn(help='"Override the default configurations of the agents"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='override', type=d.T.object)]),
    withOverrideMixin(override): { spec+: { override+: override } },
  },
  '#mixin': 'ignore',
  mixin: self,
}
